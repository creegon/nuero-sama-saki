# -*- coding: utf-8 -*-
"""
Pipeline Integration Test
å®Œæ•´ STT -> LLM -> TTS Pipeline æµ‹è¯•
å®æ—¶æŒ‡æ ‡ç»Ÿè®¡
"""

import sys
import os
import asyncio
import time
from dataclasses import dataclass, field
from typing import List, Optional

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from loguru import logger

# æ¨¡å—å¯¼å…¥
from stt.audio_capture import AudioCapture
from stt.vad import SileroVAD
from stt.transcriber import Transcriber
from llm.client import LLMClient
from llm.prompts import get_system_prompt, build_conversation_messages
from llm.stream_parser import StreamParser
from tts.synthesizer import TTSSynthesizer
from tts.audio_queue import AudioQueue
from tts.player import SequentialPlayer
from state_machine.states import State
from state_machine.transitions import StateMachine
import config

# é…ç½® loguru
logger.remove()
logger.add(
    sys.stderr, 
    level="INFO", 
    format="<green>{time:HH:mm:ss.SSS}</green> | <cyan>{name:>12}</cyan> | <level>{message}</level>"
)


@dataclass
class PipelineMetrics:
    """Pipeline æ€§èƒ½æŒ‡æ ‡"""
    # æ—¶é—´ç‚¹
    speech_end_time: float = 0
    stt_start_time: float = 0
    stt_end_time: float = 0
    llm_start_time: float = 0
    llm_first_token_time: float = 0
    llm_end_time: float = 0
    tts_first_submit_time: float = 0
    tts_first_ready_time: float = 0
    first_audio_play_time: float = 0
    all_audio_done_time: float = 0
    
    # å¥å­çº§ç»Ÿè®¡
    sentence_count: int = 0
    sentence_times: List[float] = field(default_factory=list)
    
    def calculate(self) -> dict:
        """è®¡ç®—å„é¡¹æŒ‡æ ‡"""
        return {
            "vad_to_stt": self.stt_start_time - self.speech_end_time,
            "stt_latency": self.stt_end_time - self.stt_start_time,
            "llm_ttft": self.llm_first_token_time - self.llm_start_time,
            "llm_total": self.llm_end_time - self.llm_start_time,
            "tts_first_latency": self.tts_first_ready_time - self.tts_first_submit_time,
            "speech_to_first_audio": self.first_audio_play_time - self.speech_end_time,
            "total_e2e": self.all_audio_done_time - self.speech_end_time,
            "sentence_count": self.sentence_count
        }
    
    def print_report(self):
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        metrics = self.calculate()
        
        print("\n" + "="*60)
        print("ğŸ“Š æ€§èƒ½æŒ‡æ ‡æŠ¥å‘Š")
        print("="*60)
        print(f"  VAD â†’ STT å¯åŠ¨:      {metrics['vad_to_stt']*1000:>8.1f} ms")
        print(f"  STT è¯†åˆ«è€—æ—¶:        {metrics['stt_latency']*1000:>8.1f} ms")
        print(f"  LLM é¦– Token (TTFT): {metrics['llm_ttft']*1000:>8.1f} ms")
        print(f"  LLM å®Œæ•´å“åº”:        {metrics['llm_total']*1000:>8.1f} ms")
        print(f"  TTS é¦–å¥å°±ç»ª:        {metrics['tts_first_latency']*1000:>8.1f} ms")
        print("-"*60)
        print(f"  ğŸ¯ è¯´å®Œ â†’ é¦–æ¬¡æ’­æ”¾:   {metrics['speech_to_first_audio']*1000:>8.1f} ms")
        print(f"  ğŸ“¦ ç«¯åˆ°ç«¯æ€»å»¶è¿Ÿ:      {metrics['total_e2e']*1000:>8.1f} ms")
        print(f"  ğŸ“ å¥å­æ•°é‡:          {metrics['sentence_count']:>8}")
        print("="*60)


class PipelineTest:
    """å®Œæ•´ Pipeline æµ‹è¯•"""
    
    def __init__(self):
        self.log = logger.bind(module="Pipeline")
        
        # ç»„ä»¶
        self.audio_capture: Optional[AudioCapture] = None
        self.vad: Optional[SileroVAD] = None
        self.transcriber: Optional[Transcriber] = None
        self.llm_client: Optional[LLMClient] = None
        self.stream_parser: Optional[StreamParser] = None
        self.synthesizer: Optional[TTSSynthesizer] = None
        self.audio_queue: Optional[AudioQueue] = None
        self.player: Optional[SequentialPlayer] = None
        self.state_machine: Optional[StateMachine] = None
        
        # çŠ¶æ€
        self.conversation_history: List[dict] = []
        self.current_metrics: Optional[PipelineMetrics] = None
        self._is_running = False
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        self.log.info("åˆå§‹åŒ–ç»„ä»¶...")
        
        try:
            # STT
            self.log.info("åŠ è½½ VAD...")
            self.vad = SileroVAD()
            
            self.log.info("åŠ è½½ Whisper...")
            self.transcriber = Transcriber()
            self.transcriber.load_model()
            
            self.audio_capture = AudioCapture()
            
            # LLM
            self.log.info("åˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
            self.llm_client = LLMClient()
            self.stream_parser = StreamParser()
            
            # TTS
            self.log.info("è¿æ¥ TTS æœåŠ¡...")
            self.synthesizer = TTSSynthesizer()
            if not self.synthesizer.connect():
                self.log.error("æ— æ³•è¿æ¥åˆ° IndexTTS2 æœåŠ¡")
                return False
            
            self.audio_queue = AudioQueue()
            self.player = SequentialPlayer()
            
            # çŠ¶æ€æœº
            self.state_machine = StateMachine()
            
            self.log.info("æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ âœ“")
            return True
            
        except Exception as e:
            self.log.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def process_speech(self, audio: bytes) -> Optional[str]:
        """å¤„ç†ä¸€æ¬¡è¯­éŸ³è¾“å…¥"""
        metrics = PipelineMetrics()
        metrics.speech_end_time = time.time()
        self.current_metrics = metrics
        
        # === STT ===
        self.state_machine.start_processing()
        metrics.stt_start_time = time.time()
        
        text, stats = self.transcriber.transcribe(audio)
        metrics.stt_end_time = time.time()
        
        if not text.strip():
            self.log.warning("è¯†åˆ«ç»“æœä¸ºç©º")
            self.state_machine.reset()
            return None
        
        self.log.info(f"è¯†åˆ«ç»“æœ: {text}")
        
        # === LLM ===
        messages = build_conversation_messages(text, self.conversation_history)
        
        metrics.llm_start_time = time.time()
        first_token = True
        full_response = ""
        
        self.log.info("LLM ç”Ÿæˆå›å¤...")
        
        # å…ˆæ”¶é›†å®Œæ•´ LLM å“åº”
        async for chunk in self.llm_client.chat_stream(messages, system_prompt=get_system_prompt()):
            if first_token:
                metrics.llm_first_token_time = time.time()
                first_token = False
            full_response += chunk
        
        metrics.llm_end_time = time.time()
        
        # ä½¿ç”¨æ™ºèƒ½åˆ†å‰²ï¼ˆæ”¶é›†å®Œåå†åˆ†å‰²ï¼Œæ”¯æŒåˆå¹¶çŸ­å¥å’Œé¢œæ–‡å­—ä¿æŠ¤ï¼‰
        from llm.stream_parser import split_text_to_sentences
        sentences = split_text_to_sentences(full_response)
        
        metrics.tts_first_submit_time = time.time()
        
        for sentence, emotion in sentences:
            metrics.sentence_count += 1
            self.log.info(f"å¥å­ #{metrics.sentence_count}: [{emotion}] {sentence} ({len(sentence)}å­—)")
            self.audio_queue.submit(sentence, emotion)
        
        # æ›´æ–°å¯¹è¯å†å²
        self.conversation_history.append({"role": "user", "content": text})
        self.conversation_history.append({"role": "assistant", "content": full_response})
        
        # ä¿æŒå†å²é•¿åº¦
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]
        
        return full_response
    
    async def run_single_turn(self):
        """è¿è¡Œå•è½®å¯¹è¯"""
        self.log.info("è¯·è¯´è¯...")
        self.state_machine.start_listening()
        
        if not self.audio_capture.start():
            self.log.error("éŸ³é¢‘é‡‡é›†å¯åŠ¨å¤±è´¥")
            return
        
        self.vad.reset()
        
        # ç›‘å¬è¯­éŸ³
        while True:
            chunk = self.audio_capture.read_chunk()
            if chunk is None:
                continue
            
            is_end, audio = self.vad.process_chunk(chunk)
            
            if is_end:
                self.audio_capture.stop()
                
                # å¤„ç†è¯­éŸ³
                await self.process_speech(audio)
                
                # ç­‰å¾… TTS å®Œæˆ
                self.log.info("ç­‰å¾… TTS ç”Ÿæˆ...")
                first_ready = True
                
                while self.audio_queue.has_pending():
                    await asyncio.sleep(0.1)
                    
                    # æ£€æŸ¥å¯æ’­æ”¾çš„éŸ³é¢‘
                    task = self.audio_queue.get_next_ready()
                    if task:
                        if first_ready:
                            self.current_metrics.tts_first_ready_time = time.time()
                            first_ready = False
                        
                        if task.audio_path:
                            self.player.add(task.id, task.audio_path, task.text)
                
                # å¼€å§‹æ’­æ”¾
                self.state_machine.start_speaking()
                self.current_metrics.first_audio_play_time = time.time()
                
                # ç­‰å¾…æ’­æ”¾å®Œæˆ
                while self.player.is_playing:
                    await asyncio.sleep(0.1)
                
                self.current_metrics.all_audio_done_time = time.time()
                self.state_machine.finish_speaking()
                
                # æ‰“å°æ€§èƒ½æŠ¥å‘Š
                self.current_metrics.print_report()
                
                break
    
    async def run_loop(self):
        """è¿è¡Œä¸»å¾ªç¯"""
        self._is_running = True
        self.audio_queue.start()
        self.player.start()
        
        print("\n" + "="*60)
        print("ğŸ¤ Pipeline æµ‹è¯•å·²å¯åŠ¨")
        print("   å¯¹ç€éº¦å…‹é£è¯´è¯ï¼ŒæŒ‰ Ctrl+C é€€å‡º")
        print("="*60)
        
        try:
            while self._is_running:
                await self.run_single_turn()
                print("\n" + "-"*60)
                await asyncio.sleep(0.5)
                
        except KeyboardInterrupt:
            print("\n\næ­£åœ¨é€€å‡º...")
        finally:
            self._is_running = False
            self.audio_queue.stop()
            self.player.stop()
    
    def run(self):
        """å¯åŠ¨æµ‹è¯•"""
        if not self.initialize():
            print("åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
            return
        
        asyncio.run(self.run_loop())


def main():
    print("="*60)
    print("ğŸš€ Neuro-like AI æ¡Œå®  - Pipeline é›†æˆæµ‹è¯•")
    print("="*60)
    
    print("\nå‰ç½®æ¡ä»¶æ£€æŸ¥:")
    print(f"  âœ“ LLM API: {config.LLM_API_BASE}")
    print(f"  âœ“ TTS API: {config.TTS_GRADIO_URL}")
    print(f"  âœ“ Whisper: {config.WHISPER_MODEL} ({config.WHISPER_DEVICE})")
    
    input("\næŒ‰ Enter å¼€å§‹æµ‹è¯•...")
    
    test = PipelineTest()
    test.run()


if __name__ == "__main__":
    main()
