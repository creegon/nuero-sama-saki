# -*- coding: utf-8 -*-
"""
æ€§èƒ½è¯Šæ–­å·¥å…·

å¿«é€Ÿæ£€æŸ¥ç³»ç»Ÿæ€§èƒ½çŠ¶æ€ï¼Œæä¾›è¯Šæ–­å»ºè®®
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def diagnose():
    """æ‰§è¡Œæ€§èƒ½è¯Šæ–­"""
    print("=" * 60)
    print("ğŸ¥ Neuro AI æ¡Œå®  - æ€§èƒ½è¯Šæ–­å·¥å…·")
    print("=" * 60)
    print()

    issues = []
    warnings = []

    # 1. æ£€æŸ¥GPUæ˜¾å­˜ï¼ˆä½¿ç”¨nvidia-smiï¼Œæ›´å‡†ç¡®ï¼‰
    print("ğŸ“Š [1/5] æ£€æŸ¥GPUæ˜¾å­˜...")
    try:
        import subprocess
        import re

        # ä½¿ç”¨nvidia-smiè·å–çœŸå®æ˜¾å­˜ä½¿ç”¨
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=memory.used,memory.total', '--format=csv,noheader,nounits'],
            capture_output=True,
            text=True,
            timeout=5
        )

        if result.returncode == 0:
            output = result.stdout.strip()
            match = re.search(r'(\d+),\s*(\d+)', output)
            if match:
                used_mb = int(match.group(1))
                total_mb = int(match.group(2))

                used_gb = used_mb / 1024
                total_gb = total_mb / 1024
                usage_pct = (used_mb / total_mb) * 100

                print(f"   å·²ä½¿ç”¨: {used_gb:.2f}GB ({used_mb}MB)")
                print(f"   æ€»å®¹é‡: {total_gb:.2f}GB ({total_mb}MB)")
                print(f"   ä½¿ç”¨ç‡: {usage_pct:.1f}%")

                if usage_pct > 85:
                    issues.append(f"æ˜¾å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼ˆ{usage_pct:.1f}%ï¼‰ï¼Œå¯èƒ½å¯¼è‡´OOM")
                elif usage_pct > 70:
                    warnings.append(f"æ˜¾å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼ˆ{usage_pct:.1f}%ï¼‰ï¼Œå»ºè®®é‡å¯ç¨‹åº")
                elif usage_pct > 50:
                    warnings.append(f"æ˜¾å­˜ä½¿ç”¨ä¸­ç­‰ï¼ˆ{usage_pct:.1f}%ï¼‰ï¼Œæ­£å¸¸èŒƒå›´")
            else:
                warnings.append("æ— æ³•è§£ænvidia-smiè¾“å‡º")
        else:
            # å›é€€åˆ°torchæ–¹æ³•ï¼ˆä»…å½“nvidia-smiä¸å¯ç”¨ï¼‰
            import torch
            if torch.cuda.is_available():
                total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                print(f"   è­¦å‘Š: nvidia-smiä¸å¯ç”¨ï¼Œä½¿ç”¨torchæ£€æŸ¥ï¼ˆä»…å½“å‰è¿›ç¨‹ï¼‰")
                print(f"   æ˜¾å¡æ€»é‡: {total:.2f}GB")
                warnings.append("nvidia-smiä¸å¯ç”¨ï¼Œæ˜¾å­˜æ£€æŸ¥å¯èƒ½ä¸å‡†ç¡®")
            else:
                issues.append("æœªæ£€æµ‹åˆ°CUDAï¼Œæ— æ³•ä½¿ç”¨GPUåŠ é€Ÿ")

    except subprocess.TimeoutExpired:
        warnings.append("nvidia-smiè¶…æ—¶")
    except FileNotFoundError:
        warnings.append("nvidia-smiæœªæ‰¾åˆ°ï¼ˆå¯èƒ½æœªå®‰è£…NVIDIAé©±åŠ¨ï¼‰")
    except Exception as e:
        warnings.append(f"GPUæ£€æŸ¥å¤±è´¥: {e}")

    print()

    # 2. æ£€æŸ¥Pythonå†…å­˜
    print("ğŸ“Š [2/5] æ£€æŸ¥Pythonå†…å­˜...")
    try:
        import psutil
        process = psutil.Process()
        mem = process.memory_info()
        rss_gb = mem.rss / 1024**3
        vms_gb = mem.vms / 1024**3

        print(f"   RSS: {rss_gb:.2f}GB")
        print(f"   VMS: {vms_gb:.2f}GB")

        if rss_gb > 8:
            issues.append(f"Pythonå†…å­˜ä½¿ç”¨è¿‡é«˜ï¼ˆ{rss_gb:.1f}GBï¼‰ï¼Œå»ºè®®é‡å¯ç¨‹åº")
        elif rss_gb > 4:
            warnings.append(f"Pythonå†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼ˆ{rss_gb:.1f}GBï¼‰")
    except Exception as e:
        warnings.append(f"å†…å­˜æ£€æŸ¥å¤±è´¥: {e}")

    print()

    # 3. æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶
    print("ğŸ“Š [3/5] æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶...")
    try:
        import config
        tts_dir = config.TTS_OUTPUT_DIR
        debug_dir = os.path.join(config.BASE_DIR, "debug_audio")

        tts_count = 0
        debug_count = 0

        if os.path.exists(tts_dir):
            tts_count = len([f for f in os.listdir(tts_dir) if os.path.isfile(os.path.join(tts_dir, f))])

        if os.path.exists(debug_dir):
            debug_count = len([f for f in os.listdir(debug_dir) if os.path.isfile(os.path.join(debug_dir, f))])

        print(f"   TTSä¸´æ—¶æ–‡ä»¶: {tts_count}ä¸ª")
        print(f"   DebugéŸ³é¢‘: {debug_count}ä¸ª")

        if tts_count > 100:
            warnings.append(f"TTSä¸´æ—¶æ–‡ä»¶è¿‡å¤šï¼ˆ{tts_count}ä¸ªï¼‰ï¼Œå»ºè®®æ¸…ç†")
        if debug_count > 200:
            warnings.append(f"DebugéŸ³é¢‘è¿‡å¤šï¼ˆ{debug_count}ä¸ªï¼‰ï¼Œå»ºè®®æ¸…ç†")

    except Exception as e:
        warnings.append(f"æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}")

    print()

    # 4. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    print("ğŸ“Š [4/5] æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    try:
        import config

        # æ£€æŸ¥åˆå¹¶æƒé‡
        merged_path = os.path.join(config.BASE_DIR, "checkpoints", "sakiko_merged", "tts_model_merged.pt")
        if os.path.exists(merged_path):
            print(f"   âœ“ åˆå¹¶æƒé‡å­˜åœ¨ (æ¨è)")
        else:
            warnings.append("æœªæ‰¾åˆ°åˆå¹¶æƒé‡ï¼Œæ­£åœ¨ä½¿ç”¨LoRAæ¨¡å¼ï¼ˆæ€§èƒ½è¾ƒå·®ï¼‰")
            print(f"   âœ— åˆå¹¶æƒé‡ä¸å­˜åœ¨ï¼Œä½¿ç”¨LoRAæ¨¡å¼")

        # æ£€æŸ¥LoRA checkpoint
        lora_path = config.VOXCPM_LORA_PATH
        if os.path.exists(lora_path):
            print(f"   âœ“ LoRA checkpointå­˜åœ¨")
        else:
            issues.append(f"LoRA checkpointä¸å­˜åœ¨: {lora_path}")

    except Exception as e:
        warnings.append(f"æ¨¡å‹æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}")

    print()

    # 5. æä¾›å»ºè®®
    print("ğŸ“Š [5/5] è¯Šæ–­å»ºè®®...")
    print()

    if not issues and not warnings:
        print("   âœ… ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼")
    else:
        if issues:
            print(f"   ğŸš¨ å‘ç° {len(issues)} ä¸ªä¸¥é‡é—®é¢˜:")
            for issue in issues:
                print(f"      - {issue}")
            print()

        if warnings:
            print(f"   âš ï¸ å‘ç° {len(warnings)} ä¸ªè­¦å‘Š:")
            for warning in warnings:
                print(f"      - {warning}")
            print()

    # æ“ä½œå»ºè®®
    print("ğŸ’¡ æ“ä½œå»ºè®®:")
    print()

    if issues or warnings:
        print("   1. ç«‹å³æ‰§è¡Œæ¸…ç†å‘½ä»¤:")
        print("      python scripts/cleanup_memory.py")
        print()
        print("   2. å¦‚æœé—®é¢˜æŒç»­ï¼Œé‡å¯åº”ç”¨:")
        print("      å…³é—­ç¨‹åº â†’ ç­‰å¾…10ç§’ â†’ é‡æ–°å¯åŠ¨")
        print()
        print("   3. å¦‚æœé‡å¯æ— æ•ˆï¼Œé‡å¯è®¡ç®—æœº")
        print()

    print("   4. æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
    print("      - å‡å°‘ä¸»åŠ¨å¯¹è¯é¢‘ç‡ï¼ˆä¿®æ”¹config.pyä¸­çš„PROACTIVE_CHAT_INTERVALï¼‰")
    print("      - ç¦ç”¨æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘ï¼ˆVOXCPM_USE_EMOTION_REF = Falseï¼‰")
    print("      - é™ä½Live2Då¸§ç‡ï¼ˆLIVE2D_FPS = 30ï¼‰")
    print()

    print("=" * 60)
    print()

    return len(issues) == 0


if __name__ == "__main__":
    diagnose()
