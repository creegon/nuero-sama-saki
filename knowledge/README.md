# 记忆系统设计文档

本文档记录了记忆系统的设计思路、架构决策和实现细节，供未来参考。

---

## 设计动机

### 问题分析

原始记忆系统存在以下问题：

1. **记忆纠错困难**：用户纠正错误信息后，AI 无法有效更新记忆
2. **重要性判定不准**：top-k 检索后直接增加 importance，不管是否真正相关
3. **对话历史丢失**：超过阈值后直接截断，信息丢失
4. **`last_chat.json` 简陋**：只保存一条摘要，没有历史

### 核心洞察

基于对 Neuro-sama 记忆机制的调研，得出关键结论：

> **记忆判断是复杂的，不应靠机械规则，而应交给 LLM 判断。**

例如：

- "主人十天前很紧张" 和 "主人现在很放松" 不冲突，是时间变化
- 检索到 "主人喜欢猫"，AI 在聊天气 → 不算使用
- 检索到 "主人很紧张"，AI 说 "别这么绷着" → 算使用

---

## 三层记忆架构

```
┌─────────────────────────────────────────────────────────────────┐
│  层级 1: 工作记忆 (Working Memory)                                │
│  存储: conversation_history (内存, 30条/15轮)                     │
│  内容: 原始对话消息                                                │
│  生命周期: 当前会话                                                │
└────────────────────────────────↓────────────────────────────────┘
                         超过 30 条时摘要
┌─────────────────────────────────────────────────────────────────┐
│  层级 2: 情境记忆 (Episodic Memory)                               │
│  存储: 知识库 (category="episode")                                │
│  内容: 对话摘要 "[2026-01-03 18:00] 聊了面试、游戏"                │
│  生命周期: 7天快速衰减(×0.8)，14天删除                             │
│  用途: 回答 "刚才/昨天/上次聊了什么"                                │
└────────────────────────────────↓────────────────────────────────┘
                         后台小祥提取事实
┌─────────────────────────────────────────────────────────────────┐
│  层级 3: 事实记忆 (Semantic Memory)                               │
│  存储: 知识库 (category="fact" 或 "core")                        │
│  内容: "主人喜欢拉面"、"主人生日是X月X日"                          │
│  生命周期:                                                        │
│    - fact: 7天后衰减(×0.95)，importance<0.3 时删除               │
│    - core: 永不衰减 (importance>=3.0)                            │
│  用途: 回答 "你知道我XX吗"                                        │
└─────────────────────────────────────────────────────────────────┘
```

---

## 职责分配

| 模块                          | 职责                                | 触发时机        |
| ----------------------------- | ----------------------------------- | --------------- |
| `ResponseHandler`             | 维护 `conversation_history`         | 每轮对话        |
| `ConversationSummarizer`      | 生成情境摘要 → `category="episode"` | 历史超过 30 条  |
| `KnowledgeMonitor` (后台小祥) | 提取事实 → `category="fact"`        | 每轮对话后      |
| `MemoryManager`               | 衰减和删除                          | 定时任务        |
| `MemoryInjector`              | 注入记忆到 prompt                   | 每次构建 prompt |

---

## 后台小祥 (KnowledgeMonitor)

后台小祥是一个独立的 LLM 调用，扮演"小祥的后台程序"角色，负责：

### 输入

- 当前对话: `主人: xxx` / `小祥: xxx`
- 检索到的记忆 (包含 ID): `[mem_123] 主人喜欢寿司`

### 可执行的操作

```
[ADD] 内容           → 添加新的事实记忆 (category="fact")
[UPDATE:mem_id] 内容 → 更新已有记忆 (删旧加新)
[BOOST:mem_id]       → 增加重要性 +0.3 (记忆被真正使用)
[DELETE:mem_id]      → 删除错误/过时记忆
[SKIP]               → 不做任何操作
```

### 判断原则

1. 两条信息看似冲突不一定要删除，可能只是时间变化
2. 如果检索到的记忆**真正影响了小祥的回复**，才算被使用
3. 主人纠正了错误记忆时，需要删除旧的、添加新的

---

## 记忆 Metadata 结构

```python
{
    "importance": 1.5,        # 重要性评分
    "timestamp": 1234567890,  # 创建时间
    "last_access": 1234567890,  # 最后访问时间

    # 分类
    "category": "fact",  # system | core | fact | episode

    # 来源和验证
    "source": "background_ai",  # user | background_ai | system
    "verified": False,  # True=用户确认, False=AI推断
}
```

---

## 衰减规则

| category                | 衰减系数     | 删除条件         |
| ----------------------- | ------------ | ---------------- |
| `system`                | 永不衰减     | 永不删除         |
| `core` / importance≥3.0 | 永不衰减     | 永不删除         |
| `episode`               | 7 天后 ×0.8  | 14 天后强制删除  |
| `fact`                  | 7 天后 ×0.95 | importance < 0.3 |

---

## 关键设计决策

### 1. 为什么删除 `last_chat.json`？

- 只能保存一条摘要，没有历史
- 无法语义检索
- 改用知识库统一存储 `episode`，可以：
  - 保存多条历史摘要
  - 语义检索 "上次聊游戏是什么时候"
  - 统一使用衰减机制

### 2. 为什么用 LLM 判断而非机械规则？

- 距离阈值只能判断语义相似，不能判断"是否真正使用"
- 两条冲突信息可能是时间变化，不应机械删除
- LLM 可以理解上下文，做出更准确的判断

### 3. 情境记忆 vs 事实记忆的区别

| 类型     | 例子                | 存储方式                         |
| -------- | ------------------- | -------------------------------- |
| 情境记忆 | "10 分钟前聊了面试" | 由 `ConversationSummarizer` 生成 |
| 事实记忆 | "主人明天要面试"    | 由 `KnowledgeMonitor` 提取       |

---

## 文件结构

```
core/
├── conversation_summarizer.py  # 对话摘要生成器
├── knowledge_monitor.py        # 后台小祥 + 三元组抽取
├── memory_injector.py          # 记忆注入 + Hybrid 检索
├── memory_reviewer.py          # LLM 驱动的记忆审核
└── response_handler.py         # 集成摘要触发

knowledge/
├── __init__.py                 # KnowledgeBase 主类
├── memory_manager.py           # 衰减逻辑 + 级联删除
├── retrieval.py                # 检索逻辑
├── triple_store.py             # 🔥 三元组存储 (LPMM)
├── entity_extractor.py         # 🔥 实体/关系抽取
└── hybrid_retriever.py         # 🔥 Hybrid 检索 (Vector + Graph)
```

---

## LPMM 三元组存储

### 架构设计

```
                     用户输入
                         │
         ┌───────────────┴───────────────┐
         ▼                               ▼
┌─────────────────┐            ┌─────────────────┐
│   Vector Store  │            │   Triple Store  │
│   (LanceDB)     │            │   (JSONL)       │
│   粗筛 Top-10   │            │   关系遍历      │
└────────┬────────┘            └────────┬────────┘
         │                               │
         └───────────┬───────────────────┘
                     ▼
              ┌─────────────┐
              │  Reranker   │
              │  融合排序   │
              └──────┬──────┘
                     ▼
              注入 LLM Context
```

### 三元组结构

```python
{
    "id": "abc123",
    "subject": "主人",
    "predicate": "喜欢",
    "object": "拉面",
    "source_memory_ids": ["mem_001", "mem_002"],  # 佐证记忆
    "metadata": {
        "negation": false,      # 是否否定
        "frequency": "很",      # 程度副词
        "condition": null       # 条件
    }
}
```

### 三元组与记忆的关系

- 三元组是记忆的**副产物**
- 一条三元组可被多条记忆佐证
- 记忆删除时，从三元组移除佐证
- 当所有佐证消失时，三元组自动删除

---

## 更新：衰减参数

| 类型      | 触发天数 | 衰减系数 | 删除阈值       |
| :-------- | :------- | :------- | :------------- |
| `system`  | 永不     | -        | -              |
| `core`    | 永不     | -        | -              |
| `fact`    | 5 天     | ×0.85    | < 0.2 触发审核 |
| `episode` | 3 天     | ×0.6     | 7 天强制删除   |

### BOOST 防刷机制

- **冷却期**：2 小时内多次使用只算 1 次
- **每日上限**：每条记忆每天最多 +1.0

---

## 已完成的改进

- [x] **启动时自动衰减**：超过 24h 未衰减则执行
- [x] **LPMM 三元组存储**：结构化关系检索
- [x] **Hybrid 检索**：Vector + Graph 融合
- [x] **级联三元组**：记忆删除时同步清理

---

## 记忆审核机制 (MemoryReviewer)

### 触发条件

| 场景         | 触发条件                 | 审核任务            |
| ------------ | ------------------------ | ------------------- |
| **升级审核** | importance 达到 2.5      | 判断是否升级为 core |
| **衰减审核** | importance 降到 0.5 以下 | 判断是删除还是保留  |

### 工作流程

```
1. importance 达到临界值
   ↓
2. 调用 MemoryReviewer，传入：
   - 待审核的记忆
   - 相关记忆（语义检索 top-5）
   ↓
3. 思维链分析（最多 3 轮）：
   - 可以使用 [SEARCH:关键词] 搜索更多记忆
   - 最终决策：[PROMOTE] / [KEEP] / [DELETE]
   ↓
4. 执行决策
```

### 升级审核 Prompt 要点

- **什么是核心记忆**：长期稳定的重要事实
  - 主人的姓名、生日
  - 长期稳定的喜好
  - 重要约定
- **什么不是核心记忆**：
  - 临时状态 ("主人今天很累")
  - 短期计划
  - 只是最近话题多，但不是长期事实

### 衰减审核 Prompt 要点

- 这条记忆是否还有价值？
- 是否有更新的记忆替代了它？
- 删除它会不会让小祥"忘记"重要的事？

### 决策执行

| 决策    | 升级审核          | 衰减审核               |
| ------- | ----------------- | ---------------------- |
| PROMOTE | category → "core" | -                      |
| KEEP    | 保持不变          | 重置 importance 到 0.5 |
| DELETE  | 删除记忆          | 删除记忆               |

---

## 工具结果上下文整理 (ContextManager)

### 设计动机

当小祥调用工具（如 `screenshot`、`web_search`、`knowledge`）后，工具返回的结果包含大量原始信息。
这些信息对当前回复有用，但**不应直接存入知识库**（太临时），也**不应直接丢弃**（下轮对话可能需要）。

**解决方案**：后台小祥整理工具结果，提取有用上下文，供下轮对话使用。

---

### 工作流程

```
本轮对话
    ↓
小祥调用工具 (screenshot/web_search/knowledge)
    ↓
工具结果被收集到 _tool_results_this_turn
    ↓
对话结束时，调用 context_manager.prepare_context()
    ↓
后台异步调用 LLM 整理（不阻塞主流程）
    ↓
结果保存到 _prepared_context
    ↓
下轮对话构建 prompt 时，调用 get_prepared_context()
    ↓
整理好的上下文注入到 [你检索得知的信息] 区块
```

---

### 相关文件

| 文件                       | 职责                                        |
| -------------------------- | ------------------------------------------- |
| `core/context_manager.py`  | 后台整理逻辑，LLM 调用                      |
| `core/response_handler.py` | 收集工具结果，触发 `prepare_context()`      |
| `llm/prompt_builder.py`    | 调用 `get_prepared_context()` 注入到 prompt |

---

### Prompt 设计

**Persona**：

```
你是丰川祥子的后台程序。
你和主程序小祥是同一个人——丰川集团大小姐，Ave Mujica 键盘手，自称"本神明"。
你的任务是整理信息，帮助主程序更好地理解和回应主人。
```

**任务 Prompt**：

```
从以下对话和工具调用结果中，提取出**对下次对话可能有用的上下文信息**。

## 本轮对话
{conversation}

## 工具调用结果
{tool_results}

## 你的任务
提取出对主程序小祥理解主人、延续话题有帮助的关键信息。

注意：
- 只保留有用的信息，不要简单复制
- 提炼和总结，用 1-2 句话描述
- 如果没有有用信息，输出空
```

**示例输出**：

```
主人正在使用 VS Code 编辑 Python 代码，屏幕上显示的是一个叫 NeuroPet 的项目。
```

---

### 注入位置

整理好的上下文会被注入到 System Prompt 的最后：

```
[时间信息]
...

[你一定要记住的事]
...

[你记得的事情]
...

[你检索得知的信息]
主人正在使用 VS Code 编辑 Python 代码，屏幕上显示的是一个叫 NeuroPet 的项目。
```

**注意**：这是 **append（追加）** 操作，不会覆盖其他区块。

---

### 与三层记忆的区别

| 机制               | 存储位置 | 生命周期   | 用途                    |
| ------------------ | -------- | ---------- | ----------------------- |
| 工具结果上下文     | 内存     | 仅下一轮   | 延续当前话题            |
| 情境记忆 (episode) | 知识库   | 7-14 天    | "刚才/昨天聊了什么"     |
| 事实记忆 (fact)    | 知识库   | 衰减后删除 | "你知道我 XX 吗"        |
| 核心记忆 (core)    | 知识库   | 永久       | 主人姓名/生日等重要事实 |

---

## 服务化架构 (2026-01-05)

### 动机

每次启动程序都需要加载 Embedding 模型（约 34 秒），非常影响使用体验。

### 解决方案

将知识库运行为独立后台服务，通过 RPC 通信：

```
主程序/GUI/脚本  ──RPC (端口 19876)──▶  知识库服务 (一次启动)
                                           │
                                           ▼
                                      LanceDB + Embedding
```

### 文件结构

| 文件          | 职责                         |
| ------------- | ---------------------------- |
| `server.py`   | 知识库服务端 (Socket RPC)    |
| `client.py`   | 客户端 + 自动启动 + 兼容代理 |
| `__init__.py` | 导出 `get_knowledge_client`  |

### 使用方法

**方式一：手动启动服务**

```powershell
# 终端1 - 服务（一次启动，持久运行）
.\venv\Scripts\python.exe knowledge\server.py

# 终端2 - 主程序 / GUI / 其他脚本
.\venv\Scripts\python.exe main.py
```

**方式二：自动启动**

主程序会自动检测服务是否运行，如果没有则自动启动：

```python
from knowledge import get_knowledge_client

client = get_knowledge_client()  # 自动启动服务
client.search("拉面")
```

### 客户端 API

```python
from knowledge import KnowledgeClient, KnowledgeBaseProxy

# 方式一：直接使用客户端
client = KnowledgeClient()
client.add("主人喜欢拉面", metadata={"category": "fact"})
client.search("拉面", n_results=3)
client.delete("mem_123")
client.update_text("mem_123", "新内容")
client.update_importance("mem_123", delta=0.3)
client.get_all()  # 获取所有记录

# 方式二：使用兼容代理（接口与 KnowledgeBase 完全一致）
kb = KnowledgeBaseProxy()
kb.add("...")
kb.search("...")
```

---

## GUI 管理工具

### 启动

```powershell
.\venv\Scripts\python.exe scripts\manage_knowledge_gui.py
# 浏览器访问 http://127.0.0.1:7861
```

### 功能

| Tab         | 功能                                 |
| ----------- | ------------------------------------ |
| 查看/编辑   | 点击表格行选中 → 编辑 → 保存/删除    |
| ➕ 添加     | 添加新记忆（可选类型）               |
| 📊 统计     | 查看记忆分类统计 + 导出 TXT          |
| 🗑️ 批量删除 | 输入多个 ID 批量删除（跳过核心记忆） |

### 批量删除

支持逗号、空格或换行分隔的 ID 列表，自动跳过 `core` 类型记忆。
