# -*- coding: utf-8 -*-
"""
çŸ¥è¯†åº“æ ¸å¿ƒå®ç°
"""

import os
import sys
import time
import uuid
import json
from typing import Optional, List, Dict
from loguru import logger

import config

import lancedb
import pyarrow as pa


class KnowledgeBase:
    """
    çŸ¥è¯†åº“
    
    ä½¿ç”¨ LanceDB å­˜å‚¨å’Œæ£€ç´¢çŸ¥è¯†
    æ”¯æŒè¯­ä¹‰æœç´¢ï¼Œå»¶è¿Ÿ < 10ms
    """
    
    # Embedding æ¨¡å‹é…ç½®
    EMBEDDING_MODEL = "BAAI/bge-base-zh-v1.5"  # ä¸­æ–‡ä¸“ç”¨ï¼Œ768 ç»´
    EMBEDDING_DIM = 768
    
    # è¡¨ç»“æ„
    SCHEMA = pa.schema([
        pa.field("id", pa.string()),
        pa.field("text", pa.string()),
        pa.field("metadata", pa.string()),  # JSON å­—ç¬¦ä¸²
        pa.field("vector", pa.list_(pa.float32(), 768)),  # BGE è¾“å‡º 768 ç»´
    ])
    
    def __init__(
        self,
        persist_directory: str = None,
        collection_name: str = None
    ):
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        self._json = json
        self.collection_name = collection_name or config.KNOWLEDGE_COLLECTION_NAME
        
        if persist_directory is None:
            persist_directory = config.KNOWLEDGE_LANCEDB_PATH
        
        init_start = time.time()
        logger.info(f"ğŸ“š çŸ¥è¯†åº“åˆå§‹åŒ–å¼€å§‹: {persist_directory}")
        os.makedirs(persist_directory, exist_ok=True)
        
        # ===== åŠ è½½ SentenceTransformer (ä¸»è¦è€—æ—¶ç‚¹) =====
        model_start = time.time()
        logger.info(f"ğŸ”§ åŠ è½½ Embedding æ¨¡å‹: {self.EMBEDDING_MODEL}...")
        try:
            import torch
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            
            # å»¶è¿Ÿå¯¼å…¥ï¼Œé˜²æ­¢ TF å†²çª
            from sentence_transformers import SentenceTransformer
            
            try:
                self._model = SentenceTransformer(
                    self.EMBEDDING_MODEL,
                    device=device,
                    local_files_only=True
                )
            except OSError:
                logger.warning("   æ¨¡å‹ä¸åœ¨æœ¬åœ°ç¼“å­˜ï¼Œé¦–æ¬¡ä¸‹è½½ä¸­...")
                self._model = SentenceTransformer(
                    self.EMBEDDING_MODEL,
                    device=device
                )
            
            # é¢„çƒ­
            _ = self._model.encode("é¢„çƒ­æµ‹è¯•", show_progress_bar=False)
            
            model_elapsed = time.time() - model_start
            logger.info(f"âœ… Embedding æ¨¡å‹åŠ è½½å®Œæˆ ({model_elapsed:.1f}s, device={device})")
        except Exception as e:
            logger.error(f"âŒ Embedding æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
        
        # ===== è¿æ¥ LanceDB =====
        try:
            self._db = lancedb.connect(persist_directory)
            logger.debug("âœ… LanceDB è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ LanceDB è¿æ¥å¤±è´¥: {e}")
            raise
        
        # ===== è·å–æˆ–åˆ›å»ºè¡¨ =====
        try:
            table_names = self._db.table_names()
            if self.collection_name in table_names:
                self._table = self._db.open_table(self.collection_name)
            else:
                self._table = self._db.create_table(
                    self.collection_name,
                    schema=self.SCHEMA,
                    mode="create"
                )
                logger.info(f"ğŸ“ åˆ›å»ºæ–°è¡¨: {self.collection_name}")
        except Exception as e:
            logger.error(f"âŒ è¡¨æ“ä½œå¤±è´¥: {e}")
            raise
        
        total_elapsed = time.time() - init_start
        logger.info(f"ğŸ“š çŸ¥è¯†åº“å°±ç»ª: {self.count()} æ¡è®°å½• (æ€»è€—æ—¶ {total_elapsed:.1f}s)")
    
    def _embed(self, text: str) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬çš„å‘é‡è¡¨ç¤º"""
        return self._model.encode(
            text, 
            show_progress_bar=False,
            convert_to_numpy=True
        ).tolist()
    
    def _embed_batch(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆå‘é‡ (å¼ºåˆ¶ä¸²è¡Œä»¥é¿å… Windows ä¸‹çš„æ­»é”é—®é¢˜)"""
        results = []
        for t in texts:
            vec = self._model.encode(
                t, 
                show_progress_bar=False,
                convert_to_numpy=True
            )
            results.append(vec.tolist())
        return results
    
    def add(
        self,
        text: str,
        metadata: Dict = None,
        doc_id: str = None,
        importance: float = 1.0
    ) -> str:
        """æ·»åŠ çŸ¥è¯†æ¡ç›®"""
        if doc_id is None:
            doc_id = str(uuid.uuid4())[:8]
        
        if metadata is None:
            metadata = {}
        
        metadata["importance"] = importance
        metadata["access_count"] = 0
        metadata["last_access"] = 0
        metadata["timestamp"] = time.time()
        metadata["consolidated"] = False
        
        vector = self._embed(text)
        
        self._table.add([{
            "id": doc_id,
            "text": text,
            "metadata": self._json.dumps(metadata, ensure_ascii=False),
            "vector": vector
        }])
        
        logger.debug(f"ğŸ“ æ·»åŠ çŸ¥è¯†: [{doc_id}] {text[:30]}...")
        return doc_id
    
    def add_batch(self, items: List[Dict]) -> List[str]:
        """æ‰¹é‡æ·»åŠ çŸ¥è¯†"""
        if not items:
            return []
        
        texts = [item["text"] for item in items]
        vectors = self._embed_batch(texts)
        
        rows = []
        ids = []
        for i, item in enumerate(items):
            doc_id = item.get("id", str(uuid.uuid4())[:8])
            ids.append(doc_id)
            rows.append({
                "id": doc_id,
                "text": item["text"],
                "metadata": self._json.dumps(item.get("metadata", {}), ensure_ascii=False),
                "vector": vectors[i]
            })
        
        self._table.add(rows)
        logger.info(f"ğŸ“ æ‰¹é‡æ·»åŠ  {len(items)} æ¡çŸ¥è¯†")
        return ids
    
    def search(
        self,
        query: str,
        n_results: int = 3,
        where: Dict = None
    ) -> List[Dict]:
        """è¯­ä¹‰æœç´¢"""
        start = time.time()
        query_vector = self._embed(query)
        results = self._table.search(query_vector).limit(n_results).to_list()
        elapsed = (time.time() - start) * 1000
        
        formatted = []
        for row in results:
            try:
                metadata = self._json.loads(row.get("metadata", "{}"))
            except:
                metadata = {}
            
            if where:
                match = True
                for key, value in where.items():
                    if metadata.get(key) != value:
                        match = False
                        break
                if not match:
                    continue
            
            formatted.append({
                "id": row.get("id", ""),
                "text": row.get("text", ""),
                "metadata": metadata,
                "distance": row.get("_distance", 0)
            })
        
        if formatted:
            logger.info(f"ğŸ” æœç´¢ '{query[:30]}' â†’ {len(formatted)} æ¡åŒ¹é… ({elapsed:.0f}ms)")
        else:
            logger.debug(f"ğŸ” æœç´¢ '{query[:30]}' â†’ æ— åŒ¹é… ({elapsed:.0f}ms)")
        
        return formatted
    
    def get_context_for_llm(
        self,
        query: str,
        n_results: int = 3,
        threshold: float = 1.5
    ) -> str:
        """è·å–ç”¨äº LLM çš„ä¸Šä¸‹æ–‡"""
        results = self.search(query, n_results)
        relevant = [r for r in results if r["distance"] < threshold]
        
        if not relevant:
            return ""
        
        lines = ["[ç›¸å…³çŸ¥è¯†]"]
        for r in relevant:
            lines.append(f"- {r['text']}")
        
        return "\n".join(lines)
    
    # å§”æ‰˜ç»™ Helper çš„æ–¹æ³•
    def get_recent_memories(self, n: int = 5, exclude_system: bool = True) -> str:
        from knowledge.retrieval import create_memory_retriever
        return create_memory_retriever(self).get_recent_memories(n, exclude_system)
    
    def get_important_memories(self, threshold: float = 2.5, n: int = 3) -> str:
        from knowledge.retrieval import create_memory_retriever
        return create_memory_retriever(self).get_important_memories(threshold, n)
    
    def search_by_text(self, query: str, n_results: int = 3) -> str:
        from knowledge.retrieval import create_memory_retriever
        return create_memory_retriever(self).search_by_text(query, n_results)
    
    def search_by_text_raw(self, query: str, n_results: int = 3) -> list:
        from knowledge.retrieval import create_memory_retriever
        return create_memory_retriever(self).search_by_text_raw(query, n_results)
    
    def update_importance(self, doc_id: str, delta: float = 0.5) -> bool:
        from knowledge.memory_manager import create_memory_manager
        return create_memory_manager(self).update_importance(doc_id, delta)
    
    def find_similar(self, text: str, threshold: float = 0.8) -> list:
        from knowledge.memory_manager import create_memory_manager
        return create_memory_manager(self).find_similar(text, threshold)
    
    def add_with_dedup(self, text: str, metadata: Dict = None, similarity_threshold: float = 0.85) -> str:
        from knowledge.memory_manager import create_memory_manager
        return create_memory_manager(self).add_with_dedup(text, metadata, similarity_threshold)
    
    def decay_old_memories(self, days_threshold: int = 7, decay_factor: float = 0.9) -> int:
        from knowledge.memory_manager import create_memory_manager
        return create_memory_manager(self).decay_old_memories(days_threshold, decay_factor)
    
    def delete(self, doc_id: str) -> bool:
        try:
            self._table.delete(f"id = '{doc_id}'")
            return True
        except:
            return False
    
    def count(self) -> int:
        try:
            return len(self._table.to_arrow())
        except:
            return 0
    
    def clear(self) -> None:
        try:
            self._db.drop_table(self.collection_name)
            self._table = self._db.create_table(
                self.collection_name,
                schema=self.SCHEMA,
                mode="create"
            )
            logger.warning("âš ï¸ çŸ¥è¯†åº“å·²æ¸…ç©º")
        except Exception as e:
            logger.error(f"æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥: {e}")


# å…¨å±€å•ä¾‹
_knowledge_base: Optional[KnowledgeBase] = None

def get_knowledge_base() -> KnowledgeBase:
    """è·å–å…¨å±€çŸ¥è¯†åº“å®ä¾‹"""
    global _knowledge_base
    if _knowledge_base is None:
        logger.debug("ğŸ“š é¦–æ¬¡åˆå§‹åŒ–çŸ¥è¯†åº“å•ä¾‹...")
        _knowledge_base = KnowledgeBase()
    return _knowledge_base
