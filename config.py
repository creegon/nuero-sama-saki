# Neuro-like AI Desktop Pet - Configuration

import os

# ====================
# å†…å­˜ä¼˜åŒ–é…ç½®
# ====================
# ä¼˜åŒ– CUDA å†…å­˜åˆ†é…ï¼Œå‡å°‘ç¢ç‰‡åŒ–
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:128"

# ====================
# Paths
# ====================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODELS_DIR = os.path.join(BASE_DIR, "models")

# ====================
# Antigravity LLM API
# ====================
LLM_API_BASE = "http://localhost:8045/v1"
LLM_API_KEY = "sk-text"  # Default key from antigravity2api
LLM_MODEL = "gemini-3-flash"  # High reasoning model

# ====================
# Vision Settings
# ====================
VISION_ENABLED = True
VISION_MODEL = "gemini-3-flash"  # åŒ LLM_MODEL
SCREENSHOT_MAX_SIZE = 1024       # æœ€å¤§è¾¹é•¿ (åƒç´ )
SCREENSHOT_QUALITY = 85          # JPEG è´¨é‡

# ====================
# Knowledge Base
# ====================
ENABLE_KNOWLEDGE = True  # å¯ç”¨çŸ¥è¯†åº“ (ç‹¬ç«‹è¿›ç¨‹æ¨¡å¼)
KNOWLEDGE_SERVER_HOST = "127.0.0.1"
KNOWLEDGE_SERVER_PORT = 19876
KNOWLEDGE_SOCKET_TIMEOUT = 10.0
KNOWLEDGE_LANCEDB_PATH = os.path.join(BASE_DIR, "data", "knowledge_lance")
KNOWLEDGE_COLLECTION_NAME = "sakiko_knowledge_v2"

# ====================
# Proactive Chat Settings (LLM ä¸»å¯¼æ¨¡å¼)
# ====================
PROACTIVE_CHAT_ENABLED = True

# æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰- æ¯éš”è¿™ä¸ªæ—¶é—´èŒƒå›´éšæœºæ£€æŸ¥ä¸€æ¬¡æ˜¯å¦è¦ä¸»åŠ¨è¯´è¯
PROACTIVE_CHECK_INTERVAL_MIN = 10    # æœ€çŸ­æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
PROACTIVE_CHECK_INTERVAL_MAX = 30    # æœ€é•¿æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰

# è§¦å‘æ¡ä»¶
PROACTIVE_MIN_IDLE_TIME = 10         # ç”¨æˆ·è‡³å°‘ç©ºé—²å¤šä¹…æ‰ä¼šè§¦å‘ï¼ˆç§’ï¼‰

# è¿½é—®è®¾ç½®
FOLLOW_UP_DELAY_MIN = 2              # è¿½é—®å»¶è¿Ÿæœ€å°å€¼ï¼ˆç§’ï¼‰
FOLLOW_UP_DELAY_MAX = 4              # è¿½é—®å»¶è¿Ÿæœ€å¤§å€¼ï¼ˆç§’ï¼‰

# ğŸ”¥ æ³¨æ„ï¼šå·²ç§»é™¤ PROACTIVE_CHAT_CHANCE å’Œ FOLLOW_UP_CHANCE
# ç°åœ¨å®Œå…¨ç”±åå°å°ç¥¥ï¼ˆLLMï¼‰å†³å®šæ˜¯å¦è¯´è¯ï¼Œä¸å†æœ‰æœºæ¢°æ¦‚ç‡å®¡æ ¸

# ====================
# è®°å¿†ç³»ç»Ÿé…ç½®
# ====================
MEMORY_INJECTION_COUNT = 5           # æ¯è½®æ³¨å…¥çš„è®°å¿†æ•°é‡
MEMORY_DECAY_DAYS = 7                # è¶…è¿‡å¤šå°‘å¤©æœªè®¿é—®å¼€å§‹è¡°å‡
MEMORY_DECAY_FACTOR = 0.9            # è¡°å‡ç³»æ•° (0.9 = æ¯æ¬¡é™ä½ 10%)
MEMORY_SIMILARITY_THRESHOLD = 0.85   # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆè¶…è¿‡åˆ™åˆå¹¶è®°å¿†è€Œéæ–°å¢ï¼‰
MEMORY_MIN_IMPORTANCE = 0.3          # ä½äºæ­¤é‡è¦æ€§çš„è®°å¿†ä¼šè¢«é—å¿˜
MEMORY_REFRESH_INTERVAL = 5          # æ¯ N è½®å¯¹è¯åˆ·æ–°ä¸€æ¬¡ç›¸å…³è®°å¿†
MEMORY_IMPORTANT_THRESHOLD = 2.5     # æ ¸å¿ƒå±‚è®°å¿†çš„é‡è¦æ€§é˜ˆå€¼

# ====================
# VoxCPM TTS é…ç½®
# ====================
# æ³¨æ„: ä¼˜å…ˆä½¿ç”¨ merged æ¨¡å‹ (checkpoints/sakiko_merged/tts_model_merged.pt)
#       è‹¥ merged ä¸å­˜åœ¨ï¼Œåˆ™å›é€€åˆ° LoRA æ¨¡å¼
VOXCPM_LORA_PATH = os.path.join(BASE_DIR, "checkpoints", "sakiko_lora", "step_0002000")  # LoRA å›é€€è·¯å¾„
VOXCPM_CFG_VALUE = 2.2  # é™ä½åˆ°2.2ä»¥å¹³è¡¡ç¨³å®šæ€§ä»¥å¢åŠ ç¨³å®šæ€§ï¼Œé™ä½éŸ³è°ƒå¤±æ§æ¦‚ç‡)
VOXCPM_INFERENCE_STEPS = 10  # æ¨ç†æ­¥æ•° (ä¿æŒåŸå€¼ä»¥ç»´æŒRTFæ€§èƒ½)
VOXCPM_USE_PROMPT = False  # æ˜¯å¦ä½¿ç”¨å‚è€ƒéŸ³é¢‘ (LoRA æ•ˆæœå¥½æ—¶é€šå¸¸ä¸éœ€è¦)
VOXCPM_USE_EMOTION_REF = False  # æ˜¯å¦ä½¿ç”¨æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘ (âš ï¸ å¼€å¯ä¼šå¢åŠ  ~4s å»¶è¿Ÿï¼)
# âš ï¸ FP16 åœ¨ VoxCPM åº“ä¸­å­˜åœ¨ audio_vae dtype ä¸åŒ¹é…é—®é¢˜ï¼Œæš‚æ—¶ç¦ç”¨
VOXCPM_USE_FP16 = False  # ä½¿ç”¨ FP16 ç²¾åº¦ (å½“å‰å›  audio_vae å…¼å®¹æ€§é—®é¢˜å·²ç¦ç”¨)
VOXCPM_PROMPT_WAV = None # é»˜è®¤æç¤ºéŸ³é¢‘è·¯å¾„ (None = ä¸ä½¿ç”¨)
VOXCPM_PROMPT_TEXT = None # é»˜è®¤æç¤ºéŸ³é¢‘æ–‡æœ¬

# TTS è¾“å‡ºç›®å½•
TTS_OUTPUT_DIR = os.path.join(BASE_DIR, "outputs", "tts")

# Debug: ä¿å­˜ç”Ÿæˆçš„éŸ³é¢‘åˆ° debug_audio/ ç›®å½• (ç”¨äºåæœŸåˆ†æ)
DEBUG_SAVE_AUDIO = True  # è®¾ä¸º True å¯ç”¨éŸ³é¢‘ä¿å­˜

# ====================
# Module Paths
# ====================
MODULES_DIR = os.path.join(BASE_DIR, "modules")
ANTIGRAVITY_DIR = os.path.join(MODULES_DIR, "antigravity2api-nodejs")
LIVE2D_DIR = os.path.join(MODULES_DIR, "live2d-py")

# ====================
# Live2D Settings
# ====================
LIVE2D_MODEL_PATH = os.path.join(BASE_DIR, "live2d_local", "models", "sakiko.model3.json")
LIVE2D_FPS = 60  # å¸§ç‡
LIVE2D_LIPSYNC_ENABLED = True       # å£å‹åŒæ­¥
LIVE2D_LIPSYNC_SMOOTHING = 0.25     # å£å‹å¹³æ»‘ç³»æ•° (0-1, è¶Šå¤§è¶Šå¹³æ»‘)

# ====================
# Live2D Idle åŠ¨ç”»å‚æ•°
# ====================
# 2026-01-02 æµ‹è¯•å¾—å‡ºçš„æœ€ä½³å€¼
# æ³¨æ„: è¿™ä¸ªæ¨¡å‹çš„ ParamBreath æ§åˆ¶å°¾å·´ï¼Œä¸æ˜¯èº«ä½“å‘¼å¸ï¼

# èº«ä½“å‘¼å¸æ¨¡æ‹Ÿ (ç”¨ ParamBodyAngleY å®ç°)
LIVE2D_IDLE_BODY_BREATH_ENABLED = True   # å¯ç”¨èº«ä½“å‘¼å¸
LIVE2D_IDLE_BODY_BREATH_SPEED = 0.5      # å‘¼å¸é€Ÿåº¦ (è¶Šå°è¶Šæ…¢)
LIVE2D_IDLE_BODY_BREATH_AMPLITUDE = 1.4  # å‘¼å¸å¹…åº¦ (ParamBodyAngleY èŒƒå›´ -10~10)

# å°¾å·´æ‘†åŠ¨ (ç”¨ ParamBreath å®ç°)
LIVE2D_IDLE_TAIL_ENABLED = True          # å¯ç”¨å°¾å·´æ‘†åŠ¨
LIVE2D_IDLE_TAIL_SPEED = 0.8             # å°¾å·´æ‘†åŠ¨é€Ÿåº¦
LIVE2D_IDLE_TAIL_AMPLITUDE = 1.0         # å°¾å·´æ‘†åŠ¨å¹…åº¦ (0-1)

# çœ¨çœ¼ (æ‰‹åŠ¨å®ç°ï¼Œå®˜æ–¹ UpdateBlink ä¸å·¥ä½œ)
LIVE2D_IDLE_BLINK_ENABLED = True         # å¯ç”¨çœ¨çœ¼
LIVE2D_IDLE_BLINK_INTERVAL_MIN = 2.0     # çœ¨çœ¼æœ€çŸ­é—´éš” (ç§’)
LIVE2D_IDLE_BLINK_INTERVAL_MAX = 5.0     # çœ¨çœ¼æœ€é•¿é—´éš” (ç§’)

# å¤´å‘ç‰©ç†
LIVE2D_IDLE_PHYSICS_ENABLED = True       # å¯ç”¨å¤´å‘ç‰©ç† (UpdatePhysics)

# è¡¨æƒ…è¿‡æ¸¡
LIVE2D_EXPRESSION_LERP_SPEED = 0.08      # è¡¨æƒ…è¿‡æ¸¡é€Ÿåº¦ (0.05=æ…¢~1s, 0.1=ä¸­~0.3s, 0.2=å¿«~0.15s)

# ====================
# Service Ports
# ====================
ANTIGRAVITY_PORT = 8045

# ====================
# Audio Capture
# ====================
AUDIO_SAMPLE_RATE = 16000  # 16kHz for Whisper
AUDIO_CHANNELS = 1
AUDIO_CHUNK_MS = 32  # 32ms = 512 samples (exact requirement for Silero VAD at 16kHz)
AUDIO_OUTPUT_DEVICE = None  # None = é»˜è®¤è®¾å¤‡, æˆ–æŒ‡å®šè®¾å¤‡ç´¢å¼•/åç§°

# ====================
# Silero VAD
# ====================
VAD_THRESHOLD = 0.4        # Speech probability threshold (é™ä½ä»¥æ›´å¿«æ£€æµ‹è¯­éŸ³å¼€å§‹)
VAD_MIN_SPEECH_MS = 150    # Minimum speech duration (å‡å°‘ä»¥æ›´å¿«ç¡®è®¤è¯­éŸ³)
VAD_MIN_SILENCE_MS = 500   # Silence duration to end speech
VAD_SPEECH_PAD_MS = 400    # Padding around speech (å¢åŠ ä»¥ä¿ç•™æ›´å¤šå¼€å¤´éŸ³é¢‘)

# ====================
# è¯­éŸ³è¯†åˆ« (STT) é…ç½®
# ====================
# Voice-to-LLM: ç›´æ¥å°†è¯­éŸ³å‘é€ç»™ Geminiï¼Œè·³è¿‡ STT
# ä¼˜ç‚¹ï¼šçœæ˜¾å­˜ï¼ˆ~2GBï¼‰ã€ç«¯åˆ°ç«¯ç†è§£ã€è‡ªåŠ¨å¤šè¯­è¨€
# ç¼ºç‚¹ï¼šéœ€è¦ç½‘ç»œã€éšç§è€ƒè™‘
VOICE_TO_LLM_ENABLED = True  # å¯ç”¨åè·³è¿‡ STTï¼Œè¯­éŸ³ç›´æ¥å‘ç»™ LLM

# ä¼ ç»Ÿ STT å¼•æ“ (å½“ VOICE_TO_LLM_ENABLED=False æ—¶ä½¿ç”¨)
# å¯é€‰å¼•æ“: "paraformer" (å¿«é€Ÿ, ~0.2s) æˆ– "fireredasr" (å‡†ç¡®, ~0.5s)
STT_ENGINE = "fireredasr"

# FunASR Paraformer é…ç½®
STT_MODEL = "paraformer-large-zh"  # Paraformer-Large ä¸­æ–‡æ¨¡å‹ï¼ˆå‡†ç¡®ç‡95%+ï¼‰
STT_DEVICE = "cuda"
STT_LANGUAGE = "zh"  # ä¸»è¦è¯­è¨€

# FireRedASR é…ç½® (å¯é€‰ï¼Œå‡†ç¡®ç‡æ›´é«˜ä½†é€Ÿåº¦è¾ƒæ…¢)
FIREREDASR_MODEL_DIR = os.path.join(MODULES_DIR, "FireRedASR", "pretrained_models", "FireRedASR-AED-L")

# STT åå¤„ç†é…ç½®
STT_POST_PROCESS = True  # å¯ç”¨åå¤„ç† (è¯­æ°”è¯ç§»é™¤ã€åŒéŸ³å­—çº é”™ç­‰)
STT_CUSTOM_CORRECTIONS = {
    # è‡ªå®šä¹‰çº é”™è§„åˆ™: {"é”™è¯¯è¯": "æ­£ç¡®è¯"}
    # ä¾‹å¦‚è§’è‰²åå®¹æ˜“è¢«è¯†åˆ«é”™ï¼š
    "å°è±¡": "å°ç¥¥",
    "æ™“ç¥¥": "å°ç¥¥",

}


# ====================
# Character Settings
# ====================
CHARACTER_NAME = "å°ç¥¥"

# å¯ç”¨çš„æƒ…ç»ªæ ‡ç­¾ (ç”¨äº Live2D è¡¨æƒ…é©±åŠ¨)
def get_system_prompt() -> str:
    """
    è·å–å®Œæ•´çš„ system prompt
    """
    from llm.character_prompt import get_system_prompt
    return get_system_prompt()


# ä¿ç•™ SYSTEM_PROMPT ä½œä¸ºå…¼å®¹ï¼ˆä½†æ¨èä½¿ç”¨ get_system_prompt()ï¼‰
SYSTEM_PROMPT = get_system_prompt()

# ====================
# State Machine
# ====================
STATE_IDLE = "IDLE"
STATE_LISTENING = "LISTENING"
STATE_PROCESSING = "PROCESSING"
STATE_SPEAKING = "SPEAKING"

# ====================
# TTS Queue Settings
# ====================
TTS_MAX_WORKERS = 3  # Parallel TTS generation threads

# Ensure output directories exist
os.makedirs(TTS_OUTPUT_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)
