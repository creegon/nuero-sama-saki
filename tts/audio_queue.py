# -*- coding: utf-8 -*-
"""
Audio Queue Module
å¹¶è¡Œ TTS ç”Ÿæˆ + æŒ‰åºæ’­æ”¾é˜Ÿåˆ— + Live2D å£å‹åŒæ­¥
"""

import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, Dict, List, Callable
from dataclasses import dataclass, field
from loguru import logger
import time
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config


@dataclass
class TTSTask:
    """TTS ä»»åŠ¡"""
    id: int
    text: str
    emotion: Optional[str] = None
    audio_path: Optional[str] = None
    audio_data: Optional[bytes] = None
    is_ready: bool = False
    submit_time: float = field(default_factory=time.time)
    complete_time: Optional[float] = None


class AudioQueue:
    """
    éŸ³é¢‘é˜Ÿåˆ—ç®¡ç†å™¨
    - å¹¶è¡Œç”Ÿæˆ TTS
    - æŒ‰åºæ’­æ”¾éŸ³é¢‘
    - Live2D å£å‹åŒæ­¥
    """
    
    def __init__(self, max_workers: int = 1):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=1)
        
        self._tasks: Dict[int, TTSTask] = {}
        self._task_counter = 0
        self._next_play_id = 1
        self._is_running = False
        self._interrupted = False  # ğŸ”¥ æ‰“æ–­æ ‡å¿—
        
        # å›è°ƒ
        self.on_audio_ready: Optional[Callable[[TTSTask], None]] = None
        self.on_audio_played: Optional[Callable[[TTSTask], None]] = None
        
        # Live2D å£å‹åŒæ­¥
        self._lip_sync_analyzer = None
        self._live2d_controller = None
        self._lip_sync_enabled = True
        
    def start(self):
        """å¯åŠ¨é˜Ÿåˆ—"""
        self._is_running = True
        self._task_counter = 0
        self._next_play_id = 1
        self._tasks.clear()
        
        # åˆå§‹åŒ–å£å‹åˆ†æå™¨
        self._init_lip_sync()
        
        logger.info("éŸ³é¢‘é˜Ÿåˆ—å·²å¯åŠ¨")
    
    def _init_lip_sync(self):
        """åˆå§‹åŒ–å£å‹åŒæ­¥"""
        if not self._lip_sync_enabled:
            return
        
        try:
            from live2d_local.lipsync import LipSyncAnalyzer
            from live2d_local.controller import get_live2d_controller
            
            self._lip_sync_analyzer = LipSyncAnalyzer(sample_rate=44100)
            self._live2d_controller = get_live2d_controller()
            
            if self._live2d_controller:
                logger.info("ğŸ­ Live2D å£å‹åŒæ­¥å·²å¯ç”¨")
            else:
                logger.debug("Live2D æ§åˆ¶å™¨æœªåˆå§‹åŒ–ï¼Œå£å‹åŒæ­¥å°†åœ¨æ§åˆ¶å™¨å°±ç»ªåå¯ç”¨")
                
        except ImportError as e:
            logger.warning(f"Live2D æ¨¡å—ä¸å¯ç”¨ï¼Œå£å‹åŒæ­¥å·²ç¦ç”¨: {e}")
            self._lip_sync_enabled = False
    
    def set_live2d_controller(self, controller):
        """è®¾ç½® Live2D æ§åˆ¶å™¨"""
        self._live2d_controller = controller
        if controller:
            logger.info("ğŸ­ Live2D æ§åˆ¶å™¨å·²è¿æ¥")
    
    def stop(self):
        """åœæ­¢é˜Ÿåˆ—"""
        self._is_running = False
        self._tasks.clear()
        
        # åœæ­¢å£å‹
        if self._live2d_controller:
            self._live2d_controller.stop_speaking()
        
        logger.info("éŸ³é¢‘é˜Ÿåˆ—å·²åœæ­¢")
    
    def clear(self):
        """æ¸…ç©ºé˜Ÿåˆ—ï¼ˆç”¨äºæ‰“æ–­ï¼‰"""
        import sounddevice as sd
        
        self._interrupted = True  # è®¾ç½®æ‰“æ–­æ ‡å¿—
        self._tasks.clear()
        self._next_play_id = self._task_counter + 1
        
        # ğŸ”¥ ç«‹å³åœæ­¢éŸ³é¢‘è¾“å‡º
        try:
            sd.stop()
        except:
            pass
        
        if self._live2d_controller:
            self._live2d_controller.stop_speaking()
        
        logger.info("ğŸ”‡ éŸ³é¢‘é˜Ÿåˆ—å·²æ¸…ç©ºï¼ˆæ‰“æ–­ï¼‰")
    
    def reset_interrupt(self):
        """é‡ç½®æ‰“æ–­æ ‡å¿—ï¼ˆå¼€å§‹æ–°ä¸€è½®å¯¹è¯æ—¶è°ƒç”¨ï¼‰"""
        self._interrupted = False
    
    @property
    def is_interrupted(self) -> bool:
        """æ˜¯å¦è¢«æ‰“æ–­"""
        return self._interrupted
    
    def submit(self, text: str, emotion: Optional[str] = None) -> int:
        """
        æäº¤ TTS ä»»åŠ¡
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            emotion: æƒ…æ„Ÿæ ‡ç­¾
            
        Returns:
            ä»»åŠ¡ IDï¼Œå¦‚æœè¢«æ‰“æ–­è¿”å› -1
        """
        # ğŸ”¥ å¦‚æœå·²è¢«æ‰“æ–­ï¼Œæ‹’ç»æäº¤æ–°ä»»åŠ¡
        if self._interrupted:
            logger.debug(f"TTS ä»»åŠ¡è¢«æ‹’ç»ï¼ˆæ‰“æ–­ä¸­ï¼‰: '{text[:20]}...'")
            return -1
        
        self._task_counter += 1
        task_id = self._task_counter
        
        task = TTSTask(
            id=task_id,
            text=text,
            emotion=emotion
        )
        self._tasks[task_id] = task
        
        # æäº¤åˆ°çº¿ç¨‹æ± 
        future = self.executor.submit(self._synthesize_task, task)
        future.add_done_callback(lambda f: self._on_task_done(task_id))
        
        logger.debug(f"TTS ä»»åŠ¡å·²æäº¤: #{task_id} '{text[:20]}...'")
        return task_id
    
    def _synthesize_task(self, task: TTSTask):
        """æ‰§è¡Œ TTS æµå¼åˆæˆå¹¶ç›´æ¥æ’­æ”¾ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰"""
        import queue
        import threading
        import sounddevice as sd
        import numpy as np
        
        from tts.voxcpm_engine import get_voxcpm_engine
        engine = get_voxcpm_engine()
        
        BUFFER_SIZE = 3
        RTF_WARNING_THRESHOLD = 0.95
        
        # å£å‹åˆ†æè®¾ç½®
        LIP_SYNC_CHUNK_SIZE = 1024  # æ¯ 1024 æ ·æœ¬åˆ†æä¸€æ¬¡å£å‹
        
        audio_queue = queue.Queue()
        sample_rate = engine.sample_rate
        
        # è·å–æœ€æ–°çš„ Live2D æ§åˆ¶å™¨
        if self._lip_sync_enabled and self._live2d_controller is None:
            try:
                from live2d_local.controller import get_live2d_controller
                self._live2d_controller = get_live2d_controller()
            except:
                pass
        
        def fetch_stream():
            """åå°ç”ŸæˆéŸ³é¢‘æµ"""
            gen_start = time.time()
            total_samples = 0
            chunk_count = 0
            
            try:
                for chunk in engine.synthesize_streaming(task.text, emotion=task.emotion):
                    # ğŸ”¥ æ£€æŸ¥æ‰“æ–­æ ‡å¿— - ç«‹å³åœæ­¢ç”Ÿæˆ
                    if self._interrupted:
                        logger.info(f"ğŸ”‡ TTS ç”Ÿæˆè¢«æ‰“æ–­ (ä»»åŠ¡ #{task.id})")
                        audio_queue.put(None)  # å‘é€ç»“æŸä¿¡å·
                        return
                    
                    total_samples += len(chunk)
                    chunk_count += 1
                    audio_queue.put(chunk)
                    
                    elapsed = time.time() - gen_start
                    audio_duration = total_samples / sample_rate
                    if audio_duration > 0:
                        rtf = elapsed / audio_duration
                        if rtf > RTF_WARNING_THRESHOLD and chunk_count % 5 == 0:
                            logger.warning(f"âš ï¸ RTF={rtf:.2f} > {RTF_WARNING_THRESHOLD} (Chunk #{chunk_count})")
                
                audio_queue.put(None)
                
                # ğŸ”¥ å¦‚æœå·²è¢«æ‰“æ–­ï¼Œä¸è®°å½•å®Œæˆæ—¥å¿—
                if self._interrupted:
                    return
                
                total_time = time.time() - gen_start
                audio_duration = total_samples / sample_rate
                final_rtf = total_time / audio_duration if audio_duration > 0 else 0
                logger.debug(f"TTS ç”Ÿæˆå®Œæˆ: #{task.id} RTF={final_rtf:.2f} ({chunk_count} chunks)")
                
                engine.record_rtf(final_rtf)
                
            except Exception as e:
                logger.error(f"TTS æµå¼ç”Ÿæˆå¼‚å¸¸: {e}")
                audio_queue.put(None)
        
        try:
            fetch_thread = threading.Thread(target=fetch_stream)
            fetch_thread.start()
            
            buffer = []
            all_audio = []
            
            while len(buffer) < BUFFER_SIZE:
                item = audio_queue.get()
                if item is None:
                    break
                buffer.append(item)
                all_audio.append(item)
            
            if not buffer:
                logger.warning(f"TTS ä»»åŠ¡ #{task.id} æ²¡æœ‰ç”ŸæˆéŸ³é¢‘")
                task.is_ready = True
                return
            
            # é€šçŸ¥å¼€å§‹è¯´è¯ + è®¾ç½®è¡¨æƒ…
            if self._live2d_controller:
                self._live2d_controller.start_speaking()
                # åŠ¨æ€è¡¨æƒ…åˆ‡æ¢ï¼šæ’­æ”¾æ¯æ®µæ—¶è®¾ç½®å¯¹åº”è¡¨æƒ…
                if task.emotion:
                    self._live2d_controller.set_expression(task.emotion)
            
            # æµå¼æ’­æ”¾ + å£å‹åŒæ­¥
            lip_buffer = np.array([], dtype=np.float32)
            
            with sd.OutputStream(samplerate=sample_rate, channels=1, dtype='float32') as stream:
                for chunk in buffer:
                    # ğŸ”¥ æ£€æŸ¥æ‰“æ–­æ ‡å¿—
                    if self._interrupted:
                        logger.info("ğŸ”‡ TTS æ’­æ”¾è¢«æ‰“æ–­")
                        break
                    
                    # å£å‹åŒæ­¥
                    if self._lip_sync_analyzer and self._live2d_controller:
                        lip_buffer = np.concatenate([lip_buffer, chunk.flatten()])
                        while len(lip_buffer) >= LIP_SYNC_CHUNK_SIZE:
                            lip_chunk = lip_buffer[:LIP_SYNC_CHUNK_SIZE]
                            lip_buffer = lip_buffer[LIP_SYNC_CHUNK_SIZE:]
                            
                            vowel, mouth_open, mouth_form = self._lip_sync_analyzer.analyze(lip_chunk)
                            self._live2d_controller.set_lipsync(mouth_open, mouth_form)
                    
                    if chunk.ndim == 1:
                        chunk = chunk.reshape(-1, 1)
                    stream.write(chunk)
                
                while not self._interrupted:
                    try:
                        item = audio_queue.get(timeout=0.1)  # æ·»åŠ è¶…æ—¶ä»¥ä¾¿æ£€æŸ¥æ‰“æ–­
                    except queue.Empty:
                        continue  # è¶…æ—¶åç»§ç»­æ£€æŸ¥æ‰“æ–­æ ‡å¿—
                    
                    if item is None:
                        break
                    all_audio.append(item)
                    
                    # ğŸ”¥ æ£€æŸ¥æ‰“æ–­æ ‡å¿—
                    if self._interrupted:
                        logger.info("ğŸ”‡ TTS æ’­æ”¾è¢«æ‰“æ–­")
                        break
                    
                    # å£å‹åŒæ­¥
                    if self._lip_sync_analyzer and self._live2d_controller:
                        lip_buffer = np.concatenate([lip_buffer, item.flatten()])
                        while len(lip_buffer) >= LIP_SYNC_CHUNK_SIZE:
                            lip_chunk = lip_buffer[:LIP_SYNC_CHUNK_SIZE]
                            lip_buffer = lip_buffer[LIP_SYNC_CHUNK_SIZE:]
                            
                            vowel, mouth_open, mouth_form = self._lip_sync_analyzer.analyze(lip_chunk)
                            self._live2d_controller.set_lipsync(mouth_open, mouth_form)
                    
                    if item.ndim == 1:
                        item = item.reshape(-1, 1)
                    stream.write(item)
            
            fetch_thread.join()
            
            # åœæ­¢è¯´è¯
            if self._live2d_controller:
                self._live2d_controller.stop_speaking()
            
            # é‡ç½®å£å‹åˆ†æå™¨
            if self._lip_sync_analyzer:
                self._lip_sync_analyzer.reset()
            
            # Debug: ä¿å­˜éŸ³é¢‘åˆ°æ–‡ä»¶
            debug_save = getattr(config, 'DEBUG_SAVE_AUDIO', False)
            if debug_save and all_audio:
                import scipy.io.wavfile as wav
                from datetime import datetime
                
                full_audio = np.concatenate(all_audio)
                
                debug_dir = os.path.join(config.BASE_DIR, "debug_audio")
                os.makedirs(debug_dir, exist_ok=True)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"tts_{task.id}_{timestamp}.wav"
                filepath = os.path.join(debug_dir, filename)
                
                wav.write(filepath, sample_rate, (full_audio * 32767).astype(np.int16))
                logger.info(f"ğŸ”Š Debug: éŸ³é¢‘å·²ä¿å­˜ -> {filename}")
            
            task.audio_data = b'streamed'
            task.is_ready = True
            task.complete_time = time.time()
            
        except Exception as e:
            logger.error(f"TTS ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            task.is_ready = True
            
            # ç¡®ä¿åœæ­¢è¯´è¯çŠ¶æ€
            if self._live2d_controller:
                self._live2d_controller.stop_speaking()

    
    def _on_task_done(self, task_id: int):
        """ä»»åŠ¡å®Œæˆå›è°ƒ"""
        if task_id not in self._tasks:
            return
            
        task = self._tasks[task_id]
        synth_time = task.complete_time - task.submit_time if task.complete_time else 0
        
        if task.audio_data or task.audio_path:
            logger.debug(f"TTS ä»»åŠ¡å®Œæˆ: #{task_id} (è€—æ—¶: {synth_time:.2f}s)")
            if self.on_audio_ready:
                self.on_audio_ready(task)
        else:
            logger.warning(f"TTS ä»»åŠ¡å¤±è´¥: #{task_id}")
    
    def get_next_ready(self) -> Optional[TTSTask]:
        """è·å–ä¸‹ä¸€ä¸ªå¯æ’­æ”¾çš„éŸ³é¢‘"""
        if self._next_play_id not in self._tasks:
            return None
            
        task = self._tasks[self._next_play_id]
        if task.is_ready:
            self._next_play_id += 1
            return task
        return None
    
    def get_all_ready(self) -> List[TTSTask]:
        """è·å–æ‰€æœ‰æŒ‰é¡ºåºå‡†å¤‡å¥½çš„éŸ³é¢‘"""
        ready_tasks = []
        while True:
            task = self.get_next_ready()
            if task:
                ready_tasks.append(task)
            else:
                break
        return ready_tasks
    
    def has_pending(self) -> bool:
        """æ˜¯å¦æœ‰å¾…å¤„ç†çš„ä»»åŠ¡"""
        for task in self._tasks.values():
            if not task.is_ready:
                return True
            if task.id >= self._next_play_id:
                return True
        return False
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = len(self._tasks)
        ready = sum(1 for t in self._tasks.values() if t.is_ready)
        pending = total - ready
        return {
            "total": total,
            "ready": ready,
            "pending": pending,
            "next_play_id": self._next_play_id,
            "lip_sync_enabled": self._lip_sync_enabled and self._live2d_controller is not None,
        }


# å…¨å±€å•ä¾‹
_audio_queue: Optional[AudioQueue] = None


def get_audio_queue() -> AudioQueue:
    """è·å–å…¨å±€ AudioQueue å®ä¾‹"""
    global _audio_queue
    if _audio_queue is None:
        _audio_queue = AudioQueue()
    return _audio_queue


if __name__ == "__main__":
    # æµ‹è¯•
    queue = AudioQueue()
    queue.start()
    
    sentences = [
        ("ä½ å¥½å‘€ï¼", "happy"),
        ("ä»Šå¤©å¤©æ°”çœŸä¸é”™ã€‚", "neutral"),
        ("ä¸€èµ·å‡ºå»ç©å§ï¼", "excited"),
    ]
    
    for text, emotion in sentences:
        queue.submit(text, emotion)
    
    print("ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
    import time
    while queue.has_pending():
        time.sleep(0.5)
        stats = queue.get_stats()
        print(f"  è¿›åº¦: {stats['ready']}/{stats['total']} (å£å‹åŒæ­¥: {stats['lip_sync_enabled']})")
    
    print("\næ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
    ready = queue.get_all_ready()
    for task in ready:
        print(f"  #{task.id}: {task.audio_path}")
    
    queue.stop()
