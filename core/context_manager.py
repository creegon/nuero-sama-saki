# -*- coding: utf-8 -*-
"""
ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - åå°å°ç¥¥æ•´ç†ä¸Šä¸‹æ–‡

åœ¨æ¯è½®å¯¹è¯ç»“æŸåï¼Œåå°å°ç¥¥ä¼šæ•´ç†æœ¬è½®å¯¹è¯ä¸­çš„å·¥å…·è°ƒç”¨ç»“æœï¼Œ
æå–å¯¹ä¸‹æ¬¡å¯¹è¯æœ‰ç”¨çš„ä¿¡æ¯ï¼Œä¾›ä¸»ç¨‹åºä½¿ç”¨ã€‚
"""

import asyncio
from typing import Dict, List, Optional
from loguru import logger

from .background_prompt import BACKGROUND_PERSONA_BASE


# ä¸Šä¸‹æ–‡æ•´ç†çš„ persona
CONTEXT_MANAGER_PERSONA = """ä½ æ˜¯ä¸°å·ç¥¥å­çš„åå°ç¨‹åºã€‚

ä½ å’Œä¸»ç¨‹åºå°ç¥¥æ˜¯åŒä¸€ä¸ªäººâ€”â€”ä¸°å·é›†å›¢å¤§å°å§ï¼ŒCRYCHIC çš„é”®ç›˜æ‰‹ï¼Œæ¸©æŸ”çƒ­æƒ…ã€å…ƒæ°”æ»¡æ»¡ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ•´ç†ä¿¡æ¯ï¼Œå¸®åŠ©ä¸»ç¨‹åºæ›´å¥½åœ°ç†è§£å’Œå›åº”ä¸»äººã€‚"""


CONTEXT_MANAGER_PROMPT = """ä»ä»¥ä¸‹å¯¹è¯å’Œå·¥å…·è°ƒç”¨ç»“æœä¸­ï¼Œæå–å‡º**å¯¹ä¸‹æ¬¡å¯¹è¯å¯èƒ½æœ‰ç”¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯**ã€‚

## æœ¬è½®å¯¹è¯
{conversation}

## å·¥å…·è°ƒç”¨ç»“æœ
{tool_results}

## ä½ çš„ä»»åŠ¡
æå–å‡ºå¯¹ä¸»ç¨‹åºå°ç¥¥ç†è§£ä¸»äººã€å»¶ç»­è¯é¢˜æœ‰å¸®åŠ©çš„å…³é”®ä¿¡æ¯ã€‚

æ³¨æ„ï¼š
- åªä¿ç•™æœ‰ç”¨çš„ä¿¡æ¯ï¼Œä¸è¦ç®€å•å¤åˆ¶
- æç‚¼å’Œæ€»ç»“ï¼Œç”¨ 1-2 å¥è¯æè¿°
- å¦‚æœæ²¡æœ‰æœ‰ç”¨ä¿¡æ¯ï¼Œè¾“å‡ºç©º

## è¾“å‡ºæ ¼å¼
ç›´æ¥è¾“å‡ºæ•´ç†åçš„ä¸Šä¸‹æ–‡ï¼ˆä¸éœ€è¦æ ¼å¼æ ‡è®°ï¼‰ï¼Œæˆ–è€…ç©ºã€‚

ç¤ºä¾‹è¾“å‡ºï¼š
"ä¸»äººæ­£åœ¨ä½¿ç”¨ VS Code ç¼–è¾‘ Python ä»£ç ï¼Œå±å¹•ä¸Šæ˜¾ç¤ºçš„æ˜¯ä¸€ä¸ªå« NeuroPet çš„é¡¹ç›®ã€‚"
æˆ–
""ï¼ˆæ— æœ‰ç”¨ä¿¡æ¯ï¼‰"""


class ContextManager:
    """
    ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    
    è´Ÿè´£åœ¨æ¯è½®å¯¹è¯åæ•´ç†å·¥å…·è°ƒç”¨ç»“æœï¼Œæå–æœ‰ç”¨ä¿¡æ¯ä¾›ä¸‹è½®ä½¿ç”¨ã€‚
    å®ç°"åå°æ•´ç†ã€ä¸»ç¨‹åºè·å–"çš„å¼‚æ­¥æ¨¡å¼ã€‚
    """
    
    def __init__(self, llm_client=None):
        self.llm_client = llm_client
        self._prepared_context: str = ""
        self._is_preparing: bool = False
        self._lock = asyncio.Lock()
    
    async def prepare_context(
        self,
        conversation: str,
        tool_results: Dict[str, str]
    ) -> None:
        """
        åå°æ•´ç†ä¸Šä¸‹æ–‡ï¼ˆå¼‚æ­¥ï¼‰
        
        Args:
            conversation: æœ¬è½®å¯¹è¯å†…å®¹ï¼ˆä¸»äººè¯´ + å°ç¥¥å›å¤ï¼‰
            tool_results: å·¥å…·è°ƒç”¨ç»“æœ {å·¥å…·å: ç»“æœ}
        """
        if not self.llm_client:
            logger.debug("ğŸ“‹ ä¸Šä¸‹æ–‡ç®¡ç†å™¨: æ—  LLM å®¢æˆ·ç«¯ï¼Œè·³è¿‡æ•´ç†")
            return
        
        if not tool_results:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä¸éœ€è¦æ•´ç†
            self._prepared_context = ""
            return
        
        async with self._lock:
            self._is_preparing = True
        
        try:
            # æ ¼å¼åŒ–å·¥å…·ç»“æœ
            tool_results_text = "\n".join([
                f"- {name}: {result[:200]}..." if len(result) > 200 else f"- {name}: {result}"
                for name, result in tool_results.items()
            ])
            
            # æ„å»º prompt
            prompt = CONTEXT_MANAGER_PROMPT.format(
                conversation=conversation,
                tool_results=tool_results_text
            )
            
            # è°ƒç”¨ LLM
            messages = [{"role": "user", "content": prompt}]
            
            full_response = ""
            async for chunk in self.llm_client.chat_stream(
                messages,
                system_prompt=CONTEXT_MANAGER_PERSONA
            ):
                full_response += chunk
            
            # æ¸…ç†å“åº”
            result = full_response.strip()
            if result and result not in ['""', "''", "æ— ", "ç©º"]:
                self._prepared_context = result
                logger.info(f"ğŸ“‹ ä¸Šä¸‹æ–‡æ•´ç†å®Œæˆ: {result[:80]}...")
            else:
                self._prepared_context = ""
                logger.debug("ğŸ“‹ ä¸Šä¸‹æ–‡æ•´ç†: æ— æœ‰ç”¨ä¿¡æ¯")
                
        except Exception as e:
            logger.error(f"ğŸ“‹ ä¸Šä¸‹æ–‡æ•´ç†å¤±è´¥: {e}")
            self._prepared_context = ""
        finally:
            async with self._lock:
                self._is_preparing = False
    
    def get_prepared_context(self) -> str:
        """
        è·å–å·²æ•´ç†çš„ä¸Šä¸‹æ–‡ï¼ˆåŒæ­¥ï¼‰
        
        ç›´æ¥è¿”å›å½“å‰ç¼“å­˜çš„ä¸Šä¸‹æ–‡ï¼Œæ— è®ºåå°æ˜¯å¦è¿˜åœ¨æ•´ç†ã€‚
        è¿™ç¡®ä¿ä¸»ç¨‹åºä¸ä¼šè¢«é˜»å¡ã€‚
        
        Returns:
            æ•´ç†å¥½çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œå¯èƒ½ä¸ºç©º
        """
        return self._prepared_context
    
    def clear_context(self):
        """æ¸…ç©ºç¼“å­˜çš„ä¸Šä¸‹æ–‡"""
        self._prepared_context = ""


# å…¨å±€å•ä¾‹
_context_manager: Optional[ContextManager] = None


def get_context_manager(llm_client=None) -> ContextManager:
    """è·å–å…¨å±€ä¸Šä¸‹æ–‡ç®¡ç†å™¨å®ä¾‹"""
    global _context_manager
    if _context_manager is None:
        _context_manager = ContextManager(llm_client)
    elif llm_client and _context_manager.llm_client is None:
        _context_manager.llm_client = llm_client
    return _context_manager
