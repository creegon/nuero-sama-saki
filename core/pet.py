# -*- coding: utf-8 -*-
"""
NeuroPet - AI æ¡Œå® ä¸»ç±»
"""

import asyncio
import time
from typing import Optional, List
from loguru import logger

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config



from .response_handler import ResponseHandler
from .proactive_chat import ProactiveChatManager
from .state_machine import State, StateMachine



class NeuroPet:
    """Neuro-like AI æ¡Œå® ä¸»ç±»"""
    
    def __init__(self, debug: bool = False):
        self.log = logger.bind(module="NeuroPet")
        self.debug = debug
        
        # ç»„ä»¶
        self.audio_capture: Optional[AudioCapture] = None
        self.vad: Optional[SileroVAD] = None
        self.transcriber = None
        self.llm_client: Optional[LLMClient] = None
        self.audio_queue: Optional[AudioQueue] = None
        self.player: Optional[SequentialPlayer] = None
        self.state_machine: Optional[StateMachine] = None
        
        # å“åº”å¤„ç†å™¨
        self.response_handler: Optional[ResponseHandler] = None

        # çŸ¥è¯†ç›‘æ§å™¨
        self.knowledge_monitor = None

        # å¥åº·ç›‘æ§å™¨
        self.health_monitor = None

        # ä¸»åŠ¨èŠå¤©
        self.proactive_chat: Optional[ProactiveChatManager] = None
        
        # Live2D
        self._live2d_controller = None
        self._live2d_thread = None
        self._qt_app = None
        
        self._is_running = False
        self._was_interrupted = False  # ğŸ”¥ æ‰“æ–­æ ‡å¿—
        self._append_mode = False      # ğŸ”¥ è¿½åŠ æ¨¡å¼ (åœ¨ PROCESSING é˜¶æ®µæ‰“æ–­æ—¶å¯ç”¨)
        self._pending_audio = None     # ğŸ”¥ å¾…è¿½åŠ çš„éŸ³é¢‘ (ä¸Šä¸€æ¬¡è¯´è¯çš„å†…å®¹)
        self._llm_lock = None          # ğŸ”¥ LLM å¹¶å‘é”ï¼ˆåœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­åˆå§‹åŒ–ï¼‰
        self.services = None
        self.greeter = None
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        self.log.info("=" * 50)
        self.log.info("ğŸš€ æ­£åœ¨å¯åŠ¨ Neuro-like AI æ¡Œå® ")
        self.log.info("=" * 50)
        
        try:
            # åˆå§‹åŒ–æœåŠ¡ç®¡ç†å™¨
            from core.services.background import BackgroundServices
            self.services = BackgroundServices(self)

            # ğŸ”¥ é¦–å…ˆå¯åŠ¨çŸ¥è¯†åº“æœåŠ¡ (å¼‚æ­¥åå°çº¿ç¨‹)
            # è¿™æ ·å¯ä»¥ä¸ STT/TTS åŠ è½½å¹¶è¡Œï¼ŒèŠ‚çœå¯åŠ¨æ—¶é—´
            self.services.start_knowledge_service()
            
            # STT ç»„ä»¶
            self.log.info("ğŸ“¢ åŠ è½½è¯­éŸ³æ´»åŠ¨æ£€æµ‹ (Silero VAD)...")
            from stt.vad import SileroVAD
            self.vad = SileroVAD()
            
            # Voice-to-LLM æ¨¡å¼ä¸‹è·³è¿‡ STT åŠ è½½
            if config.VOICE_TO_LLM_ENABLED:
                self.log.info("ğŸ¤ Voice-to-LLM æ¨¡å¼å¯ç”¨ - è·³è¿‡ STT åŠ è½½")
                self.transcriber = None
            else:
                self.log.info(f"ğŸ¤ åŠ è½½è¯­éŸ³è¯†åˆ« ({config.STT_ENGINE})...")
                
                # æ ¹æ®é…ç½®é€‰æ‹© STT å¼•æ“
                # STT Factory Loading
                from stt import get_transcriber
                self.transcriber = get_transcriber()
                self.transcriber.load_model()
            
            from stt.audio_capture import AudioCapture
            self.audio_capture = AudioCapture()
            
            # LLM ç»„ä»¶
            self.log.info("ğŸ§  åˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
            from llm.client import LLMClient
            self.llm_client = LLMClient()
            
            # å¥åº·ç›‘æ§å™¨ï¼ˆå…ˆåˆå§‹åŒ–ï¼Œåé¢TTSå¼•æ“ä¼šç”¨åˆ°ï¼‰
            self.log.info("ğŸ¥ åˆå§‹åŒ–å¥åº·ç›‘æ§å™¨...")
            from .health_monitor import HealthMonitor
            self.health_monitor = HealthMonitor()

            # TTS ç»„ä»¶
            self.log.info("ğŸ”Š é¢„åŠ è½½ VoxCPM TTS å¼•æ“...")
            from tts.voxcpm_engine import get_voxcpm_engine
            tts_engine = get_voxcpm_engine()
            tts_engine.initialize()

            # è®¾ç½®å¥åº·ç›‘æ§å›è°ƒ
            tts_engine.set_health_monitor(self.health_monitor)
            self.health_monitor.set_cleanup_callback(self._on_cleanup_needed)
            self.health_monitor.set_critical_callback(self._on_critical_degradation)

            self.log.info(f"   VoxCPM åŠ è½½å®Œæˆï¼Œé‡‡æ ·ç‡: {tts_engine.sample_rate}Hz")
            
            from tts.audio_queue import AudioQueue
            from tts.player import SequentialPlayer
            self.audio_queue = AudioQueue()
            self.player = SequentialPlayer()
            
            self.player.on_sentence_start = self._on_sentence_start
            self.player.on_sentence_end = self._on_sentence_end
            
            # çŠ¶æ€æœº
            # from core.state_machine import StateMachine (already imported)
            self.state_machine = StateMachine()
            self.state_machine.on_state_change = self._on_state_change

            # å“åº”å¤„ç†å™¨
            self.log.info("ğŸ”§ åˆå§‹åŒ–å“åº”å¤„ç†å™¨...")
            self.response_handler = ResponseHandler(
                llm_client=self.llm_client,
                audio_queue=self.audio_queue,
                player=self.player,
                state_machine=self.state_machine,
                knowledge_monitor=self.knowledge_monitor,
            )
            self.response_handler.set_expression_callback(self._set_expression)
            
            # ä¸»åŠ¨èŠå¤©
            from core.proactive_chat import get_proactive_chat_manager
            self.proactive_chat = get_proactive_chat_manager(llm_client=self.llm_client)
            self.proactive_chat.set_callbacks(
                on_proactive_request=self._on_proactive_chat,
                get_recent_context=lambda: self.response_handler.get_recent_context() if self.response_handler else "(æš‚æ— )"
            )
            
            # ğŸ”¥ é™é»˜å±å¹•è§‚å¯Ÿå™¨ (åå°å°ç¥¥é»˜é»˜è§‚å¯Ÿä¸»äºº)
            from core.screen_observer import get_screen_observer
            try:
                from knowledge import get_knowledge_base
                kb = get_knowledge_base()
                self.screen_observer = get_screen_observer(
                    llm_client=self.llm_client,
                    knowledge_base=kb
                )
            except Exception as e:
                self.log.warning(f"âš ï¸ å±å¹•è§‚å¯Ÿå™¨åˆå§‹åŒ–è·³è¿‡ (çŸ¥è¯†åº“æœªå°±ç»ª): {e}")
                self.screen_observer = None
            
            # åˆå§‹åŒ–è¡Œä¸º
            from core.behaviors.greeting import AutoGreeter
            self.greeter = AutoGreeter(
                self.llm_client,
                self.audio_queue,
                self.player,
                self.state_machine,
                self._set_expression
            )

            # Live2D (ç”± BackgroundServices ç®¡ç†)
            try:
                self.services.start_live2d()
            except Exception as e:
                self.log.warning(f"âš ï¸ Live2D åŠ è½½å¤±è´¥ (å¯é€‰åŠŸèƒ½): {e}")
            
            # å†…å­˜æ¸…ç†
            try:
                from scripts.cleanup_memory import start_periodic_cleanup
                start_periodic_cleanup(interval_seconds=300)
            except Exception as e:
                self.log.debug(f"å®šæœŸæ¸…ç†æœªå¯ç”¨: {e}")
            
            self.log.info("=" * 50)
            self.log.info("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ!")
            self.log.info("=" * 50)
            return True
            
        except Exception as e:
            self.log.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def _on_proactive_chat(self, system_prompt: str) -> None:
        """ä¸»åŠ¨èŠå¤©å›è°ƒ - æ¥æ”¶æ¥è‡ª proactive_chat çš„ç³»ç»Ÿæç¤ºè¯"""
        # ğŸ”¥ ç¡®ä¿é”å·²åˆå§‹åŒ–
        if self._llm_lock is None:
            self._llm_lock = asyncio.Lock()
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†å…¶ä»–è¯·æ±‚
        if self._llm_lock.locked():
            self.log.info("â³ ä¸»åŠ¨èŠå¤©è¢«è·³è¿‡ï¼šæ­£åœ¨å¤„ç†å…¶ä»–è¯·æ±‚")
            return
        
        async with self._llm_lock:
            try:
                # è·å–ä¸Šä¸‹æ–‡
                recent_context = self.response_handler.get_recent_context()
                
                # å°è¯•è·å–å±å¹•å†…å®¹
                screen_context = ""
                try:
                    from vision import get_vision_analyzer
                    analyzer = get_vision_analyzer()
                    screen_context = await analyzer.describe_for_chat("")
                except:
                    screen_context = "(æ— æ³•è·å–å±å¹•)"
                
                # æ„å»ºå®Œæ•´ prompt
                full_prompt = f"""{system_prompt}

ã€å‚è€ƒä¿¡æ¯ã€‘
å±å¹•å†…å®¹ï¼š{screen_context[:200]}
æœ€è¿‘å¯¹è¯ï¼š{recent_context}"""
                
                messages = [{"role": "user", "content": full_prompt}]
                
                full_response = ""
                print("ğŸ¤– [ä¸»åŠ¨] AI: ", end="", flush=True)
                async for chunk in self.llm_client.chat_stream(
                    messages, system_prompt=config.SYSTEM_PROMPT
                ):
                    full_response += chunk
                    print(chunk, end="", flush=True)
                print()
                
                # å¤„ç†å“åº”
                if self.response_handler.tool_executor.has_tool_call(full_response):
                    await self.response_handler._handle_tool_call("[ä¸»åŠ¨èŠå¤©]", full_response)
                else:
                    await self.response_handler._speak_response(full_response, "[ä¸»åŠ¨èŠå¤©]")
                
                self.response_handler.conversation_history.append({
                    "role": "assistant",
                    "content": f"[ä¸»åŠ¨å‘èµ·] {full_response}"
                })
                
            except Exception as e:
                self.log.error(f"ä¸»åŠ¨èŠå¤©å¤„ç†å¤±è´¥: {e}")
            
    def _set_expression(self, emotion: str) -> None:
        """è®¾ç½® Live2D è¡¨æƒ…"""
        try:
            from live2d_local import get_live2d_controller
            controller = get_live2d_controller()
            if controller:
                controller.set_expression(emotion)
        except:
            pass
    
    def _on_state_change(self, old_state: State, new_state: State):
        self.log.debug(f"çŠ¶æ€: {old_state.name} -> {new_state.name}")
    
    def _on_sentence_start(self, task_id: int, text: str):
        self.log.info(f"ğŸ—£ è¯´: {text}")
    
    def _on_sentence_end(self, task_id: int, text: str):
        pass

    def _on_cleanup_needed(self):
        """å¥åº·ç›‘æ§å›è°ƒï¼šéœ€è¦æ¸…ç†"""
        self.log.info("ğŸ§¹ å¥åº·ç›‘æ§è§¦å‘æ¸…ç†")
        from scripts.cleanup_memory import cleanup_all
        cleanup_all(aggressive=False)

    def _on_critical_degradation(self):
        """å¥åº·ç›‘æ§å›è°ƒï¼šä¸¥é‡æ€§èƒ½é€€åŒ–"""
        self.log.warning("ğŸš¨ å¥åº·ç›‘æ§æ£€æµ‹åˆ°ä¸¥é‡æ€§èƒ½é€€åŒ–")

        # æ¿€è¿›æ¸…ç†
        from scripts.cleanup_memory import cleanup_all
        cleanup_all(aggressive=True)

        # é‡è½½TTSæ¨¡å‹
        from tts.voxcpm_engine import get_voxcpm_engine
        tts_engine = get_voxcpm_engine()
        tts_engine.reload_model()

    async def process_user_speech(self, audio):
        """å¤„ç†ç”¨æˆ·è¯­éŸ³ï¼ˆæ”¯æŒæ‰“æ–­æ£€æµ‹ï¼‰
        
        Voice-to-LLM æ¨¡å¼ï¼šç›´æ¥å‘é€éŸ³é¢‘ç»™ LLM
        ä¼ ç»Ÿæ¨¡å¼ï¼šå…ˆ STT è½¬æ–‡å­—å†å‘é€
        
        åœ¨å¤„ç†æœŸé—´ï¼Œåå°æŒç»­ç›‘å¬ç”¨æˆ·çš„æ‰“æ–­
        
        ğŸ”¥ è¿½åŠ æ¨¡å¼ï¼šå¦‚æœåœ¨ PROCESSING é˜¶æ®µè¢«æ‰“æ–­ï¼Œä¼šæŠŠä¹‹å‰è¯´çš„å’Œæ–°è¯´çš„æ‹¼æ¥
        """
        import numpy as np
        
        # ğŸ”¥ ç¡®ä¿é”å·²åˆå§‹åŒ–
        if self._llm_lock is None:
            self._llm_lock = asyncio.Lock()
        
        # ğŸ”¥ è¿½åŠ æ¨¡å¼æ£€æµ‹
        if self._append_mode and self._pending_audio is not None:
            # æ‹¼æ¥ä¹‹å‰çš„éŸ³é¢‘å’Œæ–°çš„éŸ³é¢‘
            self.log.debug(f"ğŸ“ è¿½åŠ æ¨¡å¼ï¼šæ‹¼æ¥éŸ³é¢‘ (ä¹‹å‰ {len(self._pending_audio)/16000:.2f}s + æ–° {len(audio)/16000:.2f}s)")
            audio = np.concatenate([self._pending_audio, audio])
            self._append_mode = False
            self._pending_audio = None
        
        # ğŸ”¥ ä¿å­˜å½“å‰éŸ³é¢‘ç”¨äºå¯èƒ½çš„è¿½åŠ 
        self._pending_audio = audio
        
        # ğŸ”¥ é‡ç½®å–æ¶ˆæ ‡å¿—ï¼Œç¡®ä¿æ–°è¯·æ±‚ä¸å—ä¸Šä¸€ä¸ªè¢«æ‰“æ–­çš„è¯·æ±‚å½±å“
        if self.response_handler:
            self.response_handler.reset_cancellation()
        
        # æ›´æ–°äº¤äº’æ—¶é—´
        if self.proactive_chat:
            self.proactive_chat.update_interaction_time()
        
        # å¯åŠ¨åå°æ‰“æ–­æ£€æµ‹ä»»åŠ¡
        interrupt_task = asyncio.create_task(self._background_interrupt_detection())
        
        # ğŸ”¥ ä½¿ç”¨é”ä¿æŠ¤ LLM è¯·æ±‚ï¼Œç¡®ä¿ä¸ä¸ä¸»åŠ¨èŠå¤©å¹¶å‘
        async with self._llm_lock:
            try:
                if config.VOICE_TO_LLM_ENABLED:
                    # Voice-to-LLM æ¨¡å¼ï¼šç›´æ¥å‘é€éŸ³é¢‘ç»™ LLM
                    self.log.info("ğŸ¤ Voice-to-LLM: å‘é€è¯­éŸ³åˆ° LLM...")
                    self.state_machine.start_processing()
                    await self.response_handler.process_audio_input(audio, was_interrupted=self._was_interrupted)
                else:
                    # ä¼ ç»Ÿæ¨¡å¼ï¼šå…ˆè½¬å½•
                    text, stats = self.transcriber.transcribe(audio)
                    
                    if not text.strip():
                        self.log.warning("è¯†åˆ«ç»“æœä¸ºç©ºï¼Œå¿½ç•¥")
                        self.state_machine.reset()
                        return
                    
                    self.log.info(f"ğŸ‘¤ ç”¨æˆ·: {text}")
                    self.state_machine.start_processing()
                    await self.response_handler.process_user_input(text, was_interrupted=self._was_interrupted)
            finally:
                # åœæ­¢åå°æ‰“æ–­æ£€æµ‹
                interrupt_task.cancel()
                try:
                    await interrupt_task
                except asyncio.CancelledError:
                    pass
                
                # ğŸ”¥ å¦‚æœæ²¡æœ‰è¢«æ‰“æ–­ï¼Œæ¸…é™¤å¾…è¿½åŠ çš„éŸ³é¢‘
                if not self._append_mode:
                    self._pending_audio = None
    
    async def _background_interrupt_detection(self):
        """ğŸ”‡ åå°æ‰“æ–­æ£€æµ‹ä»»åŠ¡
        
        åœ¨ AI è¯´è¯æ—¶æŒç»­ç›‘å¬éº¦å…‹é£ï¼Œä¸€æ—¦æ£€æµ‹åˆ°ç”¨æˆ·å¼€å§‹è¯´è¯å°±ç«‹å³æ‰“æ–­
        
        ğŸ”¥ æ‰“æ–­æ¨¡å¼ï¼š
        - SPEAKING é˜¶æ®µæ‰“æ–­ï¼šæ­£å¸¸æ›¿æ¢ï¼Œç”¨æˆ·æ–°è¯´çš„å†…å®¹ä½œä¸ºæ–°è¾“å…¥
        - PROCESSING é˜¶æ®µæ‰“æ–­ï¼šè¿½åŠ æ¨¡å¼ï¼ŒæŠŠä¹‹å‰è¯´çš„å’Œæ–°è¯´çš„æ‹¼æ¥èµ·æ¥
        """
        # ç­‰å¾… AI å¼€å§‹è¯´è¯
        await asyncio.sleep(0.3)  # ç»™ TTS ä¸€ç‚¹å¯åŠ¨æ—¶é—´
        
        # å¯åŠ¨éŸ³é¢‘é‡‡é›†
        if not self.audio_capture.start():
            return
        
        # ç”¨äºæ£€æµ‹è¯­éŸ³å¼€å§‹çš„ç®€å•é˜ˆå€¼è®¡æ•°
        speech_frames = 0
        # ğŸ”¥ æé«˜é˜ˆå€¼ï¼Œé™ä½æ•æ„Ÿåº¦
        SPEECH_THRESHOLD = 0.5   # è¯­éŸ³æ¦‚ç‡é˜ˆå€¼ (åŸ 0.35)
        MIN_SPEECH_FRAMES = 5    # è¿ç»­å‡ å¸§è¶…è¿‡é˜ˆå€¼æ‰è®¤ä¸ºå¼€å§‹è¯´è¯ (åŸ 3ï¼Œçº¦ 160ms)
        
        # æ”¶é›†æ‰“æ–­æ—¶çš„éŸ³é¢‘
        interrupt_buffer = []
        
        try:
            while self.state_machine.is_speaking or self.state_machine.is_processing:
                chunk = self.audio_capture.read_chunk()
                if chunk is None:
                    await asyncio.sleep(0.01)
                    continue
                
                # ä¿å­˜éŸ³é¢‘åˆ°ç¼“å†²åŒº
                interrupt_buffer.append(chunk)
                # åªä¿ç•™æœ€è¿‘ 2 ç§’çš„éŸ³é¢‘ï¼ˆé¿å…å†…å­˜æ— é™å¢é•¿ï¼‰
                max_chunks = int(2.0 * 16000 / 512)  # çº¦ 62 ä¸ª chunk
                if len(interrupt_buffer) > max_chunks:
                    interrupt_buffer.pop(0)
                
                # ä½¿ç”¨ä¸» VAD æ£€æµ‹è¯­éŸ³æ¦‚ç‡
                speech_prob = self.vad.get_speech_probability(chunk)
                
                if speech_prob >= SPEECH_THRESHOLD:
                    speech_frames += 1
                    
                    # ğŸ”¥ è¿ç»­æ£€æµ‹åˆ°è¯­éŸ³ â†’ ç«‹å³æ‰“æ–­ï¼
                    if speech_frames >= MIN_SPEECH_FRAMES:
                        # ğŸ”¥ åˆ¤æ–­æ˜¯å¦åœ¨ PROCESSING é˜¶æ®µï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
                        is_processing_interrupt = self.state_machine.is_processing and not self.state_machine.is_speaking
                        
                        if is_processing_interrupt:
                            self.log.info(f"ğŸ”‡ PROCESSING é˜¶æ®µæ£€æµ‹åˆ°ç”¨æˆ·ç»§ç»­è¯´è¯ (æ¦‚ç‡: {speech_prob:.2f})ï¼Œå¯ç”¨è¿½åŠ æ¨¡å¼")
                        else:
                            self.log.info(f"ğŸ”‡ æ£€æµ‹åˆ°ç”¨æˆ·å¼€å§‹è¯´è¯ (æ¦‚ç‡: {speech_prob:.2f})ï¼Œç«‹å³æ‰“æ–­ AI")
                        
                        self.interrupt()
                        
                        # ğŸ”¥ å¦‚æœæ˜¯ PROCESSING é˜¶æ®µæ‰“æ–­ï¼Œè®¾ç½®è¿½åŠ æ ‡å¿—
                        if is_processing_interrupt:
                            self._append_mode = True  # è¿½åŠ æ¨¡å¼
                        
                        # ä¸åœæ­¢éŸ³é¢‘é‡‡é›†ï¼è®©ç”¨æˆ·ç»§ç»­è¯´
                        # ä½¿ç”¨ä¸» VAD ç»§ç»­æ”¶é›†å®Œæ•´è¯­éŸ³
                        self.vad.reset()
                        
                        # æŠŠå·²æ”¶é›†çš„éŸ³é¢‘å–‚ç»™ VAD
                        for buffered_chunk in interrupt_buffer:
                            self.vad.process_chunk(buffered_chunk)
                        
                        # ç»§ç»­æ”¶é›†ç›´åˆ°ç”¨æˆ·è¯´å®Œ
                        while True:
                            chunk = self.audio_capture.read_chunk()
                            if chunk is None:
                                await asyncio.sleep(0.01)
                                continue
                            
                            is_end, interrupt_audio = self.vad.process_chunk(chunk)
                            
                            if is_end and interrupt_audio is not None and len(interrupt_audio) > 0:
                                self.audio_capture.stop()
                                self.log.info("ğŸ¤ å¤„ç†æ‰“æ–­åçš„ç”¨æˆ·è¾“å…¥...")
                                await self.process_user_speech(interrupt_audio)
                                return
                            
                            await asyncio.sleep(0.01)
                else:
                    speech_frames = 0  # é‡ç½®è®¡æ•°
                
                await asyncio.sleep(0.01)
        except asyncio.CancelledError:
            pass
        finally:
            if self.audio_capture.is_running:
                self.audio_capture.stop()
    
    async def listen_and_respond(self):
        """ç›‘å¬ä¸€æ¬¡å¹¶å“åº”ï¼ˆæ”¯æŒæ‰“æ–­ï¼‰"""
        self.state_machine.start_listening()
        self.vad.reset()
        
        # é‡ç½®æ‰“æ–­æ ‡å¿—ï¼ˆä½†ä¸é‡ç½®è¿½åŠ æ¨¡å¼ç›¸å…³çŠ¶æ€ï¼Œå› ä¸ºå¯èƒ½è¿˜éœ€è¦è¿½åŠ ï¼‰
        self._was_interrupted = False
        self.audio_queue.reset_interrupt()
        
        if not self.audio_capture.start():
            self.log.error("éŸ³é¢‘é‡‡é›†å¯åŠ¨å¤±è´¥")
            return
        
        try:
            while self.state_machine.is_listening:
                chunk = self.audio_capture.read_chunk()
                if chunk is None:
                    continue
                
                is_end, audio = self.vad.process_chunk(chunk)
                
                if is_end:
                    self.audio_capture.stop()
                    await self.process_user_speech(audio)
                    break
                    
        except Exception as e:
            self.log.error(f"å¤„ç†å‡ºé”™: {e}")
        finally:
            if self.audio_capture.is_running:
                self.audio_capture.stop()
    
    def interrupt(self):
        """
        ğŸ”‡ æ‰“æ–­å½“å‰è¯´è¯
        
        ç«‹å³åœæ­¢ TTS æ’­æ”¾å’Œç”Ÿæˆï¼Œå‡†å¤‡å¤„ç†ç”¨æˆ·æ–°è¾“å…¥
        """
        self.log.info("ğŸ”‡ ç”¨æˆ·æ‰“æ–­äº† AI")
        
        # æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—ï¼ˆä¼šåœæ­¢æ’­æ”¾ï¼‰
        self.audio_queue.clear()
        
        # æ¸…ç©ºæ’­æ”¾å™¨é˜Ÿåˆ—
        self.player.clear()
        
        # ğŸ”¥ é€šçŸ¥ ResponseHandler å–æ¶ˆå½“å‰å¤„ç†
        if self.response_handler:
            self.response_handler.cancel()
        
        # è®¾ç½®æ‰“æ–­æ ‡å¿—
        self._was_interrupted = True
        
        # è½¬æ¢çŠ¶æ€
        self.state_machine.transition_to(State.LISTENING, force=True)
    
    async def run(self):
        """ä¸»è¿è¡Œå¾ªç¯"""
        self._is_running = True
        self.audio_queue.start()
        self.player.start()
        
        # ğŸŒ… å¯åŠ¨æ‰“æ‹›å‘¼
        if self.greeter:
            await self.greeter.run()
        
        self.log.info("")
        self.log.info("ğŸ¤ å¼€å§‹ç›‘å¬... å¯¹ç€éº¦å…‹é£è¯´è¯å§!")
        self.log.info("   æŒ‰ Ctrl+C é€€å‡º")
        self.log.info("")
        
        try:
            # å¯åŠ¨å¥åº·ç›‘æ§
            if self.health_monitor:
                self.health_monitor.start()

            # å¯åŠ¨çŸ¥è¯†ç›‘æ§å™¨ï¼ˆåœ¨äº‹ä»¶å¾ªç¯ä¸­çœŸæ­£å¯åŠ¨ï¼‰
            if self.knowledge_monitor and self.knowledge_monitor._monitor_task == "pending":
                self.knowledge_monitor._monitor_task = None
                self.knowledge_monitor.start()

            # å¯åŠ¨ä¸»åŠ¨èŠå¤©
            if self.proactive_chat:
                self.proactive_chat.start(self.state_machine)

            # ğŸ”¥ å¯åŠ¨é™é»˜å±å¹•è§‚å¯Ÿå™¨
            if self.screen_observer:
                self.screen_observer.start()

            while self._is_running:
                await self.listen_and_respond()
                await asyncio.sleep(0.3)
                
        except KeyboardInterrupt:
            self.log.info("\nğŸ‘‹ å†è§!")
        finally:
            self._is_running = False
            self.log.info("ğŸ›‘ æ­£åœ¨å…³é—­...")
            
            # ğŸ”¥ ä¿å­˜å¯¹è¯æ‘˜è¦ï¼ˆç”¨äºä¸‹æ¬¡å¯åŠ¨æ—¶çš„è®°å¿†è¿ç»­æ€§ï¼‰
            await self._save_chat_summary()

            if self.health_monitor:
                self.health_monitor.stop()
            if self.proactive_chat:
                await self.proactive_chat.stop()
            if self.knowledge_monitor:
                self.knowledge_monitor.stop()
            
            if self.services:
                self.services.stop_live2d()
            
            self.audio_queue.stop()
            self.player.stop()

            # é€€å‡ºæ—¶å¼ºåˆ¶æ¸…ç†ï¼Œé¿å…æ˜¾å­˜æ³„æ¼
            self.log.info("ğŸ§¹ é€€å‡ºæ¸…ç†ä¸­...")
            from scripts.cleanup_memory import cleanup_all
            cleanup_all(aggressive=True)

            self.log.info("âœ… é€€å‡ºå®Œæˆ")
    
    async def _save_chat_summary(self):
        """ä¿å­˜æœ¬æ¬¡å¯¹è¯æ‘˜è¦"""
        try:
            if not self.response_handler or not self.response_handler.conversation_history:
                return
            
            history = self.response_handler.conversation_history
            if len(history) < 2:
                return  # å¯¹è¯å¤ªçŸ­ï¼Œä¸ä¿å­˜
            
            # æå–æœ€è¿‘çš„å‡ è½®å¯¹è¯
            recent = history[-6:]  # æœ€è¿‘ 3 è½®
            chat_text = []
            for msg in recent:
                role = "ä¸»äºº" if msg.get("role") == "user" else "ä½ "
                content = msg.get("content", "")
                if content and content != "[è¯­éŸ³è¾“å…¥]":
                    chat_text.append(f"{role}: {content[:50]}")
            
            if not chat_text:
                return
            
            # ç”Ÿæˆç®€çŸ­æ‘˜è¦ï¼ˆç›´æ¥ç”¨è§„åˆ™ï¼Œä¸è°ƒç”¨ LLM é¿å…å»¶è¿Ÿï¼‰
            # æ‰¾åˆ°æœ€åä¸€ä¸ªæœ‰æ„ä¹‰çš„ç”¨æˆ·æ¶ˆæ¯
            summary = None
            for msg in reversed(history):
                if msg.get("role") == "user" and msg.get("content") not in ["[è¯­éŸ³è¾“å…¥]", ""]:
                    content = msg.get("content", "")[:100]
                    summary = content
                    break
            
            if not summary:
                # æ‰¾æœ€åä¸€ä¸ª AI å›å¤
                for msg in reversed(history):
                    if msg.get("role") == "assistant":
                        content = msg.get("content", "")[:100]
                        # æ¸…ç†æƒ…æ„Ÿæ ‡ç­¾
                        import re
                        content = re.sub(r'\[\w+\]\s*', '', content)
                        summary = content
                        break
            
            if summary:
                from core.memory_injector import get_memory_injector
                injector = get_memory_injector()
                injector.save_chat_summary(summary)
                self.log.info(f"ğŸ“ å¯¹è¯æ‘˜è¦å·²ä¿å­˜: {summary[:30]}...")
                
        except Exception as e:
            self.log.debug(f"ä¿å­˜å¯¹è¯æ‘˜è¦å¤±è´¥: {e}")
    
    def start(self):
        """å¯åŠ¨"""
        if not self.initialize():
            return
        asyncio.run(self.run())

