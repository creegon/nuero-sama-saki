# -*- coding: utf-8 -*-
"""
é™é»˜å±å¹•è§‚å¯Ÿå™¨ - åå°å°ç¥¥çš„"é»˜é»˜è§‚å¯Ÿ"åŠŸèƒ½

ğŸ”¥ è®¾è®¡ç†å¿µï¼š
- å®šæœŸæˆªå±è§‚å¯Ÿä¸»äººåœ¨åšä»€ä¹ˆ
- æ¨æ–­ä¸»äººçš„æ—¥å¸¸æ´»åŠ¨å’Œå–œå¥½
- ä¸æ‰“æ‰°ä¸»ç¨‹åºå°ç¥¥ï¼Œåªæ˜¯é»˜é»˜è®°ä½
- å°±åƒå® ç‰©é»˜é»˜è§‚å¯Ÿä¸»äººä¸€æ ·
"""

import asyncio
import re
import time
from typing import Optional
from loguru import logger

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

from .background_prompt import KNOWLEDGE_MONITOR_PERSONA


# ============================================================
# è§‚å¯Ÿè€… Prompt
# ============================================================

SCREEN_OBSERVER_PROMPT = f"""{KNOWLEDGE_MONITOR_PERSONA}

ä½ çš„ä»»åŠ¡æ˜¯é»˜é»˜è§‚å¯Ÿä¸»äººçš„å±å¹•ï¼Œäº†è§£ä¸»äººåœ¨åšä»€ä¹ˆã€å–œæ¬¢ä»€ä¹ˆã€‚

ã€å½“å‰å±å¹•ã€‘
ï¼ˆå›¾ç‰‡ï¼‰

ã€æˆ‘å·²ç»çŸ¥é“çš„å…³äºä¸»äººçš„ä¿¡æ¯ã€‘
{{known_facts}}

è¯·åˆ†æè¿™å¼ æˆªå›¾ï¼Œæ€è€ƒï¼š
1. ä¸»äººæ­£åœ¨åšä»€ä¹ˆï¼Ÿï¼ˆå…·ä½“æè¿°æ´»åŠ¨ï¼‰
2. è¿™èƒ½å‘Šè¯‰æˆ‘å…³äºä¸»äººçš„ä»€ä¹ˆï¼Ÿï¼ˆå…´è¶£/ä¹ æƒ¯/èŒä¸š/åå¥½ï¼‰
3. æœ‰æ²¡æœ‰ä»€ä¹ˆ**æ–°å‘ç°**æ˜¯æˆ‘ä¹‹å‰ä¸çŸ¥é“çš„ï¼Ÿ

**åˆ¤æ–­æ ‡å‡†ï¼š**
- âœ… å€¼å¾—è®°ä½ï¼šå‘ç°ä¸»äººçš„å…´è¶£çˆ±å¥½ï¼ˆå¦‚å–œæ¬¢æŸç±»æ¸¸æˆ/éŸ³ä¹/åŠ¨æ¼«ï¼‰
- âœ… å€¼å¾—è®°ä½ï¼šå‘ç°ä¸»äººçš„å·¥ä½œ/å­¦ä¹ é¢†åŸŸï¼ˆå¦‚ç¨‹åºå‘˜/å­¦ç”Ÿ/è®¾è®¡å¸ˆï¼‰
- âœ… å€¼å¾—è®°ä½ï¼šå‘ç°ä¸»äººå¸¸ç”¨çš„è½¯ä»¶/ç½‘ç«™
- âŒ ä¸éœ€è¦è®°ï¼šæ™®é€šçš„æ—¥å¸¸æ“ä½œï¼ˆæ‰“å¼€æ–‡ä»¶å¤¹ã€æµè§ˆç½‘é¡µï¼‰
- âŒ ä¸éœ€è¦è®°ï¼šå·²ç»çŸ¥é“çš„ä¿¡æ¯ï¼ˆé‡å¤è§‚å¯Ÿï¼‰
- âŒ ä¸éœ€è¦è®°ï¼šä¸´æ—¶çŠ¶æ€ï¼ˆæ­£åœ¨åŠ è½½ã€æ­£åœ¨ä¸‹è½½ï¼‰

**è¾“å‡ºæ ¼å¼ï¼š**
å¦‚æœæœ‰æ–°å‘ç°ï¼Œç”¨ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆå¯ä»¥å¤šæ¡ï¼‰ï¼š
[OBSERVE] æˆ‘è§‚å¯Ÿåˆ°ä¸»äººxxxï¼ˆæ¨æ–­ï¼šä¸»äººå¯èƒ½å–œæ¬¢/ç»å¸¸/æ“…é•¿xxxï¼‰

å¦‚æœæ²¡æœ‰æ–°å‘ç°æˆ–åªæ˜¯æ™®é€šæ´»åŠ¨ï¼Œè¾“å‡ºï¼š
[SKIP] åŸå› ï¼ˆå¦‚ï¼šåªæ˜¯æ™®é€šæ“ä½œ/å·²ç»çŸ¥é“äº†ï¼‰
"""


class ScreenObserver:
    """
    é™é»˜å±å¹•è§‚å¯Ÿå™¨
    
    å®šæœŸæˆªå±è®©åå°å°ç¥¥åˆ†æï¼Œæ¨æ–­ä¸»äººçš„è¡Œä¸ºåå¥½
    """
    
    # é»˜è®¤é…ç½®
    DEFAULT_INTERVAL = 120  # 2 åˆ†é’Ÿ
    
    def __init__(self, llm_client, knowledge_base):
        self.llm_client = llm_client
        self.kb = knowledge_base
        
        # ä»é…ç½®è¯»å–å‚æ•°
        self.enabled = getattr(config, 'SCREEN_OBSERVER_ENABLED', True)
        self.interval = getattr(config, 'SCREEN_OBSERVER_INTERVAL', self.DEFAULT_INTERVAL)
        
        self._task: Optional[asyncio.Task] = None
        self._is_running = False
        self._last_observation = ""  # é¿å…é‡å¤è§‚å¯Ÿ
        
        logger.info(f"ğŸ‘ï¸ é™é»˜å±å¹•è§‚å¯Ÿå™¨å·²åˆå§‹åŒ– (é—´éš”={self.interval}s)")
    
    def start(self):
        """å¯åŠ¨è§‚å¯Ÿå™¨"""
        if not self.enabled:
            logger.info("ğŸ‘ï¸ é™é»˜å±å¹•è§‚å¯Ÿå™¨å·²ç¦ç”¨")
            return
        
        if self._task is not None:
            return
        
        try:
            loop = asyncio.get_running_loop()
            self._is_running = True
            self._task = loop.create_task(self._observe_loop())
            logger.info(f"ğŸ‘ï¸ é™é»˜å±å¹•è§‚å¯Ÿå™¨å·²å¯åŠ¨ (æ¯ {self.interval}s è§‚å¯Ÿä¸€æ¬¡)")
        except RuntimeError:
            logger.warning("âš ï¸ äº‹ä»¶å¾ªç¯æœªè¿è¡Œï¼Œè§‚å¯Ÿå™¨å°†å»¶è¿Ÿå¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢è§‚å¯Ÿå™¨"""
        self._is_running = False
        if self._task:
            self._task.cancel()
            self._task = None
        logger.info("ğŸ‘ï¸ é™é»˜å±å¹•è§‚å¯Ÿå™¨å·²åœæ­¢")
    
    async def _observe_loop(self):
        """è§‚å¯Ÿå¾ªç¯"""
        # é¦–æ¬¡ç­‰å¾…ä¸€æ®µæ—¶é—´å†å¼€å§‹
        await asyncio.sleep(30)
        
        while self._is_running:
            try:
                await self._do_observation()
                await asyncio.sleep(self.interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ğŸ‘ï¸ è§‚å¯Ÿå¤±è´¥: {e}")
                await asyncio.sleep(60)  # å‡ºé”™åç­‰å¾…æ›´ä¹…
    
    async def _do_observation(self):
        """æ‰§è¡Œä¸€æ¬¡è§‚å¯Ÿ"""
        try:
            # 1. æˆªå±
            from vision import get_screen_capture
            screen_capture = get_screen_capture()
            screenshot = screen_capture.capture(mode="full")
            
            logger.debug(f"ğŸ‘ï¸ æˆªå±å®Œæˆ: {screenshot.width}x{screenshot.height}")
            
            # 2. è·å–å·²çŸ¥ä¿¡æ¯ï¼ˆç”¨äºé¿å…é‡å¤ï¼‰
            known_facts = self._get_known_facts()
            
            # 3. æ„å»º prompt
            prompt = SCREEN_OBSERVER_PROMPT.format(known_facts=known_facts)
            
            # 4. è°ƒç”¨ LLM åˆ†æï¼ˆå¸¦å›¾ç‰‡ï¼‰
            messages = [{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/{screenshot.format};base64,{screenshot.base64_data}"
                        }
                    }
                ]
            }]
            
            response = ""
            async for chunk in self.llm_client.chat_stream(messages, max_tokens=200):
                response += chunk
            
            logger.debug(f"ğŸ‘ï¸ è§‚å¯Ÿç»“æœ: {response[:100]}...")
            
            # 5. è§£æå¹¶å­˜å‚¨
            await self._process_observation(response)
            
        except Exception as e:
            logger.error(f"ğŸ‘ï¸ è§‚å¯Ÿæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _get_known_facts(self) -> str:
        """è·å–å·²çŸ¥çš„ä¸»äººä¿¡æ¯ï¼ˆç”¨äºé¿å…é‡å¤è§‚å¯Ÿï¼‰"""
        try:
            # è·å– observation ç±»å‹çš„è®°å¿†
            all_rows = self.kb._table.to_pandas()
            observations = []
            
            for _, row in all_rows.iterrows():
                import json
                metadata = json.loads(row.get("metadata", "{}"))
                if metadata.get("category") == "observation":
                    text = row.get("text", "")
                    if text:
                        observations.append(f"- {text[:80]}")
            
            # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘ 5 æ¡
            if observations:
                recent = observations[-5:]
                return "\n".join(recent)
            return "(æš‚æ— )"
            
        except Exception as e:
            logger.debug(f"è·å–å·²çŸ¥ä¿¡æ¯å¤±è´¥: {e}")
            return "(æš‚æ— )"
    
    async def _process_observation(self, response: str):
        """å¤„ç†è§‚å¯Ÿç»“æœ"""
        lines = response.strip().split("\n")
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # [SKIP] - è·³è¿‡
            if "[SKIP]" in line:
                reason = line.replace("[SKIP]", "").strip()
                logger.debug(f"ğŸ‘ï¸ è§‚å¯Ÿè·³è¿‡: {reason[:50]}")
                continue
            
            # [OBSERVE] - æ–°å‘ç°
            if "[OBSERVE]" in line:
                content = line.replace("[OBSERVE]", "").strip()
                if content:
                    # é¿å…å®Œå…¨é‡å¤çš„è§‚å¯Ÿ
                    if content == self._last_observation:
                        logger.debug(f"ğŸ‘ï¸ è·³è¿‡é‡å¤è§‚å¯Ÿ: {content[:30]}...")
                        continue
                    
                    # å­˜å…¥çŸ¥è¯†åº“ï¼ˆä½¿ç”¨å»é‡ï¼‰
                    doc_id = self.kb.add_with_dedup(
                        text=content,
                        metadata={
                            "category": "observation",
                            "source": "screen_observer",
                            "importance": 0.8,  # è§‚å¯Ÿå¾—åˆ°çš„ä¿¡æ¯åˆå§‹é‡è¦æ€§è¾ƒä½
                            "timestamp": time.time(),
                        },
                        similarity_threshold=0.85
                    )
                    
                    self._last_observation = content
                    logger.info(f"ğŸ‘ï¸ å±å¹•è§‚å¯Ÿå™¨ [OBSERVE]: [{doc_id}]")
                    logger.debug(f"   ğŸ“ å†…å®¹: {content}")


# å…¨å±€å•ä¾‹
_screen_observer: Optional[ScreenObserver] = None


def get_screen_observer(llm_client=None, knowledge_base=None) -> Optional[ScreenObserver]:
    """è·å–å…¨å±€å±å¹•è§‚å¯Ÿå™¨å®ä¾‹"""
    global _screen_observer
    if _screen_observer is None:
        if llm_client is None or knowledge_base is None:
            return None
        _screen_observer = ScreenObserver(llm_client, knowledge_base)
    return _screen_observer
